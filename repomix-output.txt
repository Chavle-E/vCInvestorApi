This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2024-12-08T12:00:27.597Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
api/
  v1/
    endpoints/
      auth.py
      export.py
      investment_funds.py
      investors.py
      users.py
      utils.py
    dependencies.py
middleware/
  auth.py
schemas/
  auth/
    auth_schema.py
scripts/
  import_data.py
  reset_database.py
  update_schema.py
services/
  investor_service.py
app.py
crud.py
database.py
models.py
requirements.txt
schemas.py

================================================================
Repository Files
================================================================

================
File: api/v1/endpoints/auth.py
================
from fastapi import APIRouter, HTTPException, Depends
from sqlalchemy.orm import Session
from database import get_db
from models import User
from middleware.auth import create_token, SUBSCRIPTION_LIMITS
from pydantic import BaseModel, EmailStr
from typing import Optional
import logging
import traceback

logger = logging.getLogger(__name__)

router = APIRouter()


class UserCreate(BaseModel):
    email: EmailStr
    name: Optional[str] = None


@router.post("/login")
async def login(email: str, db: Session = Depends(get_db)):
    """Login user with email - simplified auth for MVP"""
    try:
        user = db.query(User).filter(User.email == email).first()

        if not user:
            # Create new user with free tier for MVP
            user = User(
                email=email,
                subscription_tier="free",
                subscription_status="active",
                **SUBSCRIPTION_LIMITS["free"]
            )
            db.add(user)
            db.commit()
            db.refresh(user)

        # Create JWT token
        token = create_token(user.id, user.email)

        return {
            "access_token": token,
            "token_type": "bearer",
            "user": {
                "id": user.id,
                "email": user.email,
                "subscription_tier": user.subscription_tier,
                "subscription_status": user.subscription_status,
                "monthly_searches_remaining": (
                    None if user.monthly_search_limit == -1
                    else max(0, user.monthly_search_limit - user.monthly_searches)
                )
            }
        }
    except Exception as e:
        logger.error(f"Login error: {str(e)}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail="Internal server error")


@router.post("/register")
async def register(user_data: UserCreate, db: Session = Depends(get_db)):
    """Register new user"""
    logger.info(f"Registration attempt for email: {user_data.email}")
    try:
        # Check if user exists
        if db.query(User).filter(User.email == user_data.email).first():
            logger.warning(f"Registration failed: Email already exists - {user_data.email}")
            raise HTTPException(status_code=400, detail="Email already registered")

        # Create new user
        try:
            user = User(
                email=user_data.email,
                name=user_data.name,
                subscription_tier="free",
                subscription_status="active",
                **SUBSCRIPTION_LIMITS["free"]
            )
            logger.debug(f"Creating user object: {user.__dict__}")

            db.add(user)
            db.commit()
            db.refresh(user)
            logger.info(f"User created successfully: {user.id}")

        except Exception as e:
            logger.error(f"Database error during user creation: {str(e)}")
            logger.error(traceback.format_exc())
            db.rollback()
            raise HTTPException(status_code=500, detail="Database error during user creation")

        # Create token
        try:
            token = create_token(user.id, user.email)
            logger.debug("Token created successfully")
        except Exception as e:
            logger.error(f"Token creation failed: {str(e)}")
            logger.error(traceback.format_exc())
            raise HTTPException(status_code=500, detail="Token creation failed")

        return {
            "access_token": token,
            "token_type": "bearer",
            "user": {
                "id": user.id,
                "email": user.email,
                "name": user.name,
                "subscription": {
                    "tier": user.subscription_tier,
                    "status": user.subscription_status
                }
            }
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Unexpected error during registration: {str(e)}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail="Internal server error")

================
File: api/v1/endpoints/export.py
================
# api/v1/endpoints/export.py

from fastapi import APIRouter, Depends, HTTPException, Request, Query
from sqlalchemy.orm import Session
from database import get_db
from models import Investor, InvestmentFund
import logging
from fastapi.responses import StreamingResponse
import io
import csv

router = APIRouter()
logger = logging.getLogger(__name__)


def check_export_permission(user):
    """Check if user has permission to export data"""
    if not user.can_export:
        raise HTTPException(
            status_code=403,
            detail="Your subscription tier doesn't include export functionality"
        )


def generate_csv(data, headers):
    """Generate CSV file from data"""
    output = io.StringIO()
    writer = csv.DictWriter(output, fieldnames=headers)
    writer.writeheader()

    for row in data:
        # Clean row data
        clean_row = {}
        for key in headers:
            value = row.get(key)
            if isinstance(value, (list, tuple)):
                clean_row[key] = ", ".join(str(x) for x in value if x)
            else:
                clean_row[key] = value
        writer.writerow(clean_row)

    output.seek(0)
    return output


@router.get("/investors/csv")
async def export_investors_csv(
        request: Request,
        db: Session = Depends(get_db),
        limit: int = Query(1000, le=5000)
):
    """Export investors to CSV - premium feature"""
    try:
        user = request.state.user
        check_export_permission(user)

        # Get all investors
        investors = db.query(Investor).limit(limit).all()

        # Convert to dict
        investor_data = []
        for inv in investors:
            data = {
                "id": inv.id,
                "first_name": inv.first_name,
                "last_name": inv.last_name,
                "firm_name": inv.firm_name,
                "city": inv.city,
                "state": inv.state,
                "country": inv.country,
                "type_of_financing": inv.type_of_financing,
                "industry_preferences": inv.industry_preferences,
                "stage_preferences": inv.stage_preferences,
                "capital_managed": inv.capital_managed,
                "min_investment": inv.min_investment
            }

            # Only include contact info for higher tiers
            if user.can_see_contact_info:
                data.update({
                    "email": inv.email,
                    "phone": inv.phone,
                    "office_website": inv.office_website
                })

            investor_data.append(data)

        # Generate CSV
        headers = list(investor_data[0].keys()) if investor_data else []
        output = generate_csv(investor_data, headers)

        # Return streaming response
        response = StreamingResponse(
            iter([output.getvalue()]),
            media_type="text/csv",
            headers={
                'Content-Disposition': f'attachment; filename="investors.csv"'
            }
        )

        return response

    except Exception as e:
        logger.error(f"Error exporting investors: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/funds/csv")
async def export_funds_csv(
        request: Request,
        db: Session = Depends(get_db),
        limit: int = Query(1000, le=5000)
):
    """Export investment funds to CSV - premium feature"""
    try:
        user = request.state.user
        check_export_permission(user)

        # Get all funds
        funds = db.query(InvestmentFund).limit(limit).all()

        # Convert to dict
        fund_data = []
        for fund in funds:
            data = {
                "id": fund.id,
                "firm_name": fund.firm_name,
                "firm_type": fund.firm_type,
                "firm_city": fund.firm_city,
                "firm_state": fund.firm_state,
                "firm_country": fund.firm_country,
                "financing_type": fund.financing_type,
                "industry_preferences": fund.industry_preferences,
                "stage_preferences": fund.stage_preferences,
                "capital_managed": fund.capital_managed,
                "min_investment": fund.min_investment,
                "max_investment": fund.max_investment,
            }

            # Only include contact info for higher tiers
            if user.can_see_contact_info:
                data.update({
                    "contact_email": fund.contact_email,
                    "contact_phone": fund.contact_phone,
                    "firm_email": fund.firm_email,
                    "firm_phone": fund.firm_phone,
                    "firm_website": fund.firm_website
                })

            fund_data.append(data)

        # Generate CSV
        headers = list(fund_data[0].keys()) if fund_data else []
        output = generate_csv(fund_data, headers)

        # Return streaming response
        response = StreamingResponse(
            iter([output.getvalue()]),
            media_type="text/csv",
            headers={
                'Content-Disposition': f'attachment; filename="investment_funds.csv"'
            }
        )

        return response

    except Exception as e:
        logger.error(f"Error exporting funds: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

================
File: api/v1/endpoints/investment_funds.py
================
from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy import or_, and_, cast, ARRAY, String, func, text
from sqlalchemy.sql import expression
from sqlalchemy.orm import Session
from typing import List, Dict
import models
import schemas
from database import get_db
import crud
import logging

router = APIRouter()
logger = logging.getLogger(__name__)


@router.post("/", response_model=None)
def create_fund(fund: schemas.InvestmentFundCreate, db: Session = Depends(get_db)):
    try:
        return crud.investment_fund.create(db=db, obj_in=fund)
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.get("/", response_model=None)
def read_funds(
        db: Session = Depends(get_db),
        page: int = Query(1, gt=0, description="Page number"),
        per_page: int = Query(50, gt=0, le=100, description="Items per page")
):
    try:
        # Get total count
        total = db.query(models.InvestmentFund).count()

        # Calculate skip
        skip = (page - 1) * per_page

        # Get paginated results
        funds = crud.investment_fund.get_multi(
            db=db,
            skip=skip,
            limit=per_page
        )

        return {
            "total": total,
            "page": page,
            "per_page": per_page,
            "total_pages": -(-total // per_page),
            "data": funds
        }
    except Exception as e:
        logger.error(f"Error fetching funds: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/{fund_id}", response_model=None)
def read_fund(fund_id: int, db: Session = Depends(get_db)):
    try:
        db_fund = crud.investment_fund.get(db, id=fund_id)
        if db_fund is None:
            raise HTTPException(status_code=404, detail="Investment Fund not found")
        return db_fund
    except ValueError as e:
        raise HTTPException(status_code=422, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.put("/{fund_id}", response_model=None)
def update_fund(fund_id: int, fund: schemas.InvestmentFundCreate, db: Session = Depends(get_db)):
    try:
        db_fund = crud.investment_fund.update(db, id=fund_id, obj_in=fund)
        if db_fund is None:
            raise HTTPException(status_code=404, detail="Investment Fund not found")
        return db_fund
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.delete("/{fund_id}", response_model=None)
def delete_fund(fund_id: int, db: Session = Depends(get_db)):
    try:
        db_fund = crud.investment_fund.delete(db, id=fund_id)
        if db_fund is None:
            raise HTTPException(status_code=404, detail="Investment Fund not found")
        return db_fund
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.post("/search")
async def search_funds(
        filters: schemas.InvestmentFundFilterParams,
        db: Session = Depends(get_db),
        page: int = Query(1, gt=0),
        per_page: int = Query(50, gt=1, le=100)
):
    try:
        query = db.query(models.InvestmentFund)

        # Basic text search
        if filters.searchTerm:
            search = f"%{filters.searchTerm}%"
            query = query.filter(or_(
                models.InvestmentFund.firm_name.ilike(search),
                models.InvestmentFund.full_name.ilike(search),
                models.InvestmentFund.firm_email.ilike(search),
                models.InvestmentFund.contact_email.ilike(search),
                models.InvestmentFund.description.ilike(search)
            ))

        # Location filters
        if filters.location:
            if filters.location.city:
                query = query.filter(or_(*[
                    models.InvestmentFund.firm_city.ilike(f"%{city}%")
                    for city in filters.location.city
                ]))
            if filters.location.state:
                query = query.filter(or_(*[
                    models.InvestmentFund.firm_state.ilike(f"%{state}%")
                    for state in filters.location.state
                ]))
            if filters.location.country:
                query = query.filter(or_(*[
                    models.InvestmentFund.firm_country.ilike(f"%{country}%")
                    for country in filters.location.country
                ]))
            if filters.location.location_preferences and len(filters.location.location_preferences) > 0:
                query = query.filter(
                    models.InvestmentFund.geographic_preferences.op('&&')(
                        cast(filters.location.location_preferences, ARRAY(String))
                    )
                )

        # Contact info filters
        if filters.contactInfo:
            if filters.contactInfo.hasEmail:
                query = query.filter(or_(
                    models.InvestmentFund.firm_email.isnot(None),
                    models.InvestmentFund.contact_email.isnot(None)
                ))
            if filters.contactInfo.hasPhone:
                query = query.filter(or_(
                    models.InvestmentFund.firm_phone.isnot(None),
                    models.InvestmentFund.contact_phone.isnot(None)
                ))
            if filters.contactInfo.hasAddress:
                query = query.filter(and_(
                    models.InvestmentFund.firm_address.isnot(None),
                    models.InvestmentFund.firm_city.isnot(None)
                ))

        # Industry filters
        if filters.industry and filters.industry.industries:
            query = query.filter(
                models.InvestmentFund.industry_preferences.op('&&')(
                    cast(filters.industry.industries, ARRAY(String))
                )
            )
        # Fund type filter
        if filters.fundType and filters.fundType.types:
            query = query.filter(or_(*[
                or_(
                    models.InvestmentFund.firm_type.ilike(f"%{t}%"),
                    models.InvestmentFund.financing_type.ilike(f"%{t}%")
                ) for t in filters.fundType.types
            ]))

        # Investment stages
        if filters.stages and filters.stages.stages:
            query = query.filter(
                models.InvestmentFund.stage_preferences.op('&&')(
                    cast(filters.stages.stages, ARRAY(String))
                )
            )

        # Investment ranges
        if filters.investmentRanges:
            from api.v1.dependencies import parse_investment_range

            if filters.investmentRanges.assetsUnderManagement:
                min_val, max_val = parse_investment_range(filters.investmentRanges.assetsUnderManagement)
                if min_val is not None:
                    query = query.filter(models.InvestmentFund.capital_managed >= min_val)
                if max_val is not None:
                    query = query.filter(models.InvestmentFund.capital_managed <= max_val)

            if filters.investmentRanges.minInvestment:
                min_val, max_val = parse_investment_range(filters.investmentRanges.minInvestment)
                if min_val is not None:
                    query = query.filter(models.InvestmentFund.min_investment >= min_val)
                if max_val is not None:
                    query = query.filter(models.InvestmentFund.min_investment <= max_val)

        # Calculate pagination
        total = query.count()
        skip = (page - 1) * per_page
        results = query.offset(skip).limit(per_page).all()

        return {
            "total": total,
            "page": page,
            "per_page": per_page,
            "total_pages": -(-total // per_page),
            "results": [crud.investment_fund.to_dict(r) for r in results]
        }

    except Exception as e:
        logger.error(f"Error searching investment funds: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

================
File: api/v1/endpoints/investors.py
================
from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy import or_, cast, ARRAY, String
from sqlalchemy.orm import Session
import models
import schemas
from database import get_db
import crud
import logging

router = APIRouter()
logger = logging.getLogger(__name__)


@router.post("/", response_model=None)
def create_investor(investor: schemas.InvestorCreate, db: Session = Depends(get_db)):
    try:
        return crud.investor.create(db=db, obj_in=investor)
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.get("/", response_model=None)
def read_investors(
        db: Session = Depends(get_db),
        page: int = Query(1, gt=0, description="Page number"),
        per_page: int = Query(50, gt=0, le=100, description="Number of items per page"),
):
    try:
        # Get Total Count
        total = db.query(models.Investor).count()

        # Calculate Offset
        skip = (page - 1) * per_page

        # Get paginated results
        investors = crud.investor.get_multi(
            db=db,
            skip=skip,
            limit=per_page,
        )

        return {
            "total": total,
            "page": page,
            "per_page": per_page,
            "total_pages": -(-total // per_page),
            "data": investors,
        }
    except Exception as e:
        logger.error(f"Error fetching investors: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/{investor_id}", response_model=None)  # Remove response model
def read_investor(investor_id: int, db: Session = Depends(get_db)):
    try:
        db_investor = crud.investor.get(db, id=investor_id)
        if db_investor is None:
            raise HTTPException(status_code=404, detail="Investor not found")
        return db_investor
    except ValueError as e:
        raise HTTPException(status_code=422, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.put("/{investor_id}", response_model=None)
def update_investor(investor_id: int, investor: schemas.InvestorCreate, db: Session = Depends(get_db)):
    try:
        db_investor = crud.investor.update(db, id=investor_id, obj_in=investor)
        if db_investor is None:
            raise HTTPException(status_code=404, detail="Investor not found")
        return db_investor
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.delete("/{investor_id}", response_model=None)
def delete_investor(investor_id: int, db: Session = Depends(get_db)):
    try:
        db_investor = crud.investor.delete(db, id=investor_id)
        if db_investor is None:
            raise HTTPException(status_code=404, detail="Investor not found")
        return db_investor
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.post("/search")
async def search_investors(
        filters: schemas.InvestorFilterParams,
        db: Session = Depends(get_db),
        page: int = Query(1, gt=0),
        per_page: int = Query(50, gt=1, le=100)
):
    try:
        query = db.query(models.Investor)

        # Basic text search
        if filters.searchTerm:
            search = f"%{filters.searchTerm}%"
            query = query.filter(or_(
                models.Investor.first_name.ilike(search),
                models.Investor.last_name.ilike(search),
                models.Investor.firm_name.ilike(search),
                models.Investor.email.ilike(search),
                models.Investor.contact_title.ilike(search)
            ))

        # Location filters
        if filters.location:
            if filters.location.city:
                query = query.filter(or_(*[
                    models.Investor.city.ilike(f"%{city}%")
                    for city in filters.location.city
                ]))
            if filters.location.state:
                query = query.filter(or_(*[
                    models.Investor.state.ilike(f"%{state}%")
                    for state in filters.location.state
                ]))
            if filters.location.country:
                query = query.filter(or_(*[
                    models.Investor.country.ilike(f"%{country}%")
                    for country in filters.location.country
                ]))
            if filters.location.location_preferences and len(filters.location.location_preferences) > 0:
                query = query.filter(
                    models.Investor.geographic_preferences.op('&&')(
                        cast(filters.location.location_preferences, ARRAY(String))
                    )
                )

        # Contact info filters
        if filters.contactInfo:
            if filters.contactInfo.hasEmail:
                query = query.filter(models.Investor.email.isnot(None))
            if filters.contactInfo.hasPhone:
                query = query.filter(models.Investor.phone.isnot(None))
            if filters.contactInfo.hasAddress:
                query = query.filter(models.Investor.city.isnot(None))

        # Industry preferences
        if filters.industry and filters.industry.industries:
            query = query.filter(
                models.Investor.industry_preferences.op('&&')(
                    cast(filters.industry.industries, ARRAY(String))
                )
            )

        # Fund type filter
        if filters.fundType and filters.fundType.types:
            query = query.filter(
                models.Investor.type_of_financing.in_(filters.fundType.types)
            )

        # Investment stages
        if filters.stages and filters.stages.stages:
            query = query.filter(
                models.Investor.stage_preferences.op('&&')(
                    cast(filters.stages.stages, ARRAY(String))
                )
            )

        # Investment ranges
        if filters.investmentRanges:
            from api.v1.dependencies import parse_investment_range

            if filters.investmentRanges.assetsUnderManagement:
                min_val, max_val = parse_investment_range(filters.investmentRanges.assetsUnderManagement)
                if min_val is not None:
                    query = query.filter(models.Investor.capital_managed >= min_val)
                if max_val is not None:
                    query = query.filter(models.Investor.capital_managed <= max_val)

            if filters.investmentRanges.minInvestment:
                min_val, max_val = parse_investment_range(filters.investmentRanges.minInvestment)
                if min_val is not None:
                    query = query.filter(models.Investor.min_investment >= min_val)
                if max_val is not None:
                    query = query.filter(models.Investor.min_investment <= max_val)

        # Calculate pagination
        total = query.count()
        skip = (page - 1) * per_page
        results = query.offset(skip).limit(per_page).all()

        return {
            "total": total,
            "page": page,
            "per_page": per_page,
            "total_pages": -(-total // per_page),
            "results": [crud.investor.to_dict(r) for r in results]
        }

    except Exception as e:
        logger.error(f"Error searching investors: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

================
File: api/v1/endpoints/users.py
================
# api/v1/endpoints/users.py

from fastapi import APIRouter, Depends, HTTPException, Request
from sqlalchemy.orm import Session
from database import get_db
from models import User
import logging
from datetime import datetime, timezone

router = APIRouter()
logger = logging.getLogger(__name__)


@router.get("/me")
async def get_current_user(request: Request, db: Session = Depends(get_db)):
    """Get current user profile and usage stats"""
    try:
        user = request.state.user
        if not user:
            raise HTTPException(status_code=404, detail="User not found")

        # Calculate searches remaining
        searches_remaining = None if user.monthly_search_limit == -1 else \
            max(0, user.monthly_search_limit - user.monthly_searches)

        return {
            "id": user.id,
            "email": user.email,
            "subscription": {
                "tier": user.subscription_tier,
                "status": user.subscription_status,
                "end_date": user.subscription_end,
            },
            "features": {
                "can_export": user.can_export,
                "can_see_full_profiles": user.can_see_full_profiles,
                "can_see_contact_info": user.can_see_contact_info
            },
            "usage": {
                "monthly_searches": user.monthly_searches,
                "total_searches": user.total_searches,
                "searches_remaining": searches_remaining,
                "search_limit": user.monthly_search_limit
            }
        }
    except Exception as e:
        logger.error(f"Error getting user profile: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.put("/subscription")
async def update_subscription(
        request: Request,
        new_tier: str,
        db: Session = Depends(get_db)
):
    """Update user's subscription tier - called from your frontend when subscription changes"""
    try:
        user = request.state.user
        if not user:
            raise HTTPException(status_code=404, detail="User not found")

        # Update subscription
        from middleware.auth import SUBSCRIPTION_LIMITS
        if new_tier not in SUBSCRIPTION_LIMITS:
            raise HTTPException(status_code=400, detail="Invalid subscription tier")

        # Apply new limits
        limits = SUBSCRIPTION_LIMITS[new_tier]
        user.subscription_tier = new_tier
        user.monthly_search_limit = limits["monthly_searches"]
        user.can_export = limits["can_export"]
        user.can_see_full_profiles = limits["can_see_full_profiles"]
        user.can_see_contact_info = limits["can_see_contact_info"]

        db.commit()

        return {"status": "success", "tier": new_tier}

    except Exception as e:
        logger.error(f"Error updating subscription: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/reset-usage")
async def reset_usage_stats(request: Request, db: Session = Depends(get_db)):
    """Reset monthly usage counters - typically called by a CRON job"""
    try:
        user = request.state.user
        if not user:
            raise HTTPException(status_code=404, detail="User not found")

        user.monthly_searches = 0
        user.last_search = datetime.now(timezone.utc)
        db.commit()

        return {"status": "success"}

    except Exception as e:
        logger.error(f"Error resetting usage: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

================
File: api/v1/endpoints/utils.py
================
from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.orm import Session
from typing import Dict
import models
from database import get_db
import logging

router = APIRouter()
logger = logging.getLogger(__name__)


@router.get("/stats")
def get_database_stats(db: Session = Depends(get_db)) -> Dict:
    """Get database statistics"""
    try:
        total_investors = db.query(models.Investor).count()
        total_funds = db.query(models.InvestmentFund).count()
        return {
            "total_investors": total_investors,
            "total_investment_funds": total_funds
        }
    except Exception as e:
        logger.error(f"Error getting stats: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/test-pagination")
def test_pagination(
        db: Session = Depends(get_db),
        page: int = Query(1, gt=0),
        per_page: int = Query(100, gt=0, le=500)
):
    """Test Pagination with metrics"""
    try:
        skip = (page - 1) * per_page

        # Get Investors
        total_investors = db.query(models.Investor).count()
        investors = db.query(models.Investor).offset(skip).limit(per_page).all()

        # Get Investment Funds
        total_funds = db.query(models.InvestmentFund).count()
        funds = db.query(models.InvestmentFund).offset(skip).limit(per_page).all()

        return {
            "pagination": {
                "page": page,
                "per_page": per_page,
                "total_investors": total_investors,
                "total_funds": total_funds,
                "total_pages_investors": -(-total_investors // per_page),
                "total_pages_funds": -(-total_funds // per_page),
            },
            "current_page_data": {
                "investor_count": len(investors),
                "funds_count": len(funds),
                "skip": skip,
                "investors_sample": [{"id": inv.id, "email": inv.email} for inv in investors[:5]],
                "funds_sample": [{"id": fund.id, "name": fund.firm_name} for fund in funds[:5]]
            }
        }
    except Exception as e:
        logger.error(f"Error in test-pagination: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

================
File: api/v1/dependencies.py
================
from typing import Optional, Tuple


def parse_investment_range(range_str: str) -> Tuple[Optional[float], Optional[float]]:
    """Convert string investment range to numeric min/max values"""
    if not range_str:
        return None, None

    ranges = {
        # Assets Under Management
        "1B_PLUS": (1_000_000_000, None),
        "100M_500M": (100_000_000, 500_000_000),
        "500M_1B": (500_000_000, 1_000_000_000),
        "25M_100M": (25_000_000, 100_000_000),
        "0_25M": (0, 25_000_000),

        # Min Investment
        "25K_250K": (25_000, 250_000),
        "250K_1M": (250_000, 1_000_000),
        "1M_5M": (1_000_000, 5_000_000),
        "5M_PLUS": (5_000_000, None),

        # Max Investment
        "25M_150M": (25_000_000, 150_000_000),
        "10M_25M": (10_000_000, 25_000_000),
        "1M_10M": (1_000_000, 10_000_000),
        "150M_PLUS": (150_000_000, None)
    }

    return ranges.get(range_str, (None, None))

================
File: middleware/auth.py
================
from datetime import datetime, timezone, timedelta
from fastapi import Request, HTTPException, Depends
import jwt
from sqlalchemy.orm import Session
from database import get_db
from models import User
import os
import logging
import traceback

logger = logging.getLogger(__name__)

JWT_SECRET = os.getenv('JWT_SECRET', 'your-secret-key')  # Change in production
JWT_ALGORITHM = "HS256"

SUBSCRIPTION_LIMITS = {
    "free": {
        "monthly_searches": 10,
        "can_export": False,
        "can_see_full_profiles": False,
        "can_see_contact_info": False
    },
    "basic": {
        "monthly_searches": 500,
        "can_export": True,
        "can_see_full_profiles": True,
        "can_see_contact_info": False
    },
    "professional": {
        "monthly_searches": -1,  # Unlimited
        "can_export": True,
        "can_see_full_profiles": True,
        "can_see_contact_info": True
    }
}


def create_token(user_id: int, email: str) -> str:
    """Create JWT token"""
    expires = datetime.now(timezone.utc) + timedelta(days=30)
    payload = {
        "user_id": user_id,
        "email": email,
        "exp": expires
    }
    return jwt.encode(payload, JWT_SECRET, algorithm=JWT_ALGORITHM)


def decode_token(token: str) -> dict:
    """Decode JWT token"""
    try:
        return jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALGORITHM])
    except jwt.ExpiredSignatureError:
        raise HTTPException(status_code=401, detail="Token expired")
    except jwt.InvalidTokenError:
        raise HTTPException(status_code=401, detail="Invalid token")


class AuthMiddleware:
    async def __call__(self, request: Request, db: Session = Depends(get_db)):
        logger.debug(f"Processing request: {request.method} {request.url.path}")
        try:
            # Skip auth for login/register endpoints
            if request.url.path.startswith("/api/v1/auth"):
                return

            auth = request.headers.get("Authorization")
            if not auth or not auth.startswith("Bearer "):
                logger.warning("No token provided in Authorization header")
                raise HTTPException(status_code=401, detail="Missing token")

            token = auth.split(" ")[1]
            try:
                payload = decode_token(token)
                logger.debug(f"Token decoded for user_id: {payload.get('user_id')}")
            except Exception as e:
                logger.error(f"Token decode error: {str(e)}")
                raise HTTPException(status_code=401, detail="Invalid token")

            # Get user from database
            user = db.query(User).filter(User.id == payload["user_id"]).first()
            if not user:
                logger.warning(f"User not found for id: {payload['user_id']}")
                raise HTTPException(status_code=401, detail="User not found")

            logger.debug(f"Auth successful for user: {user.id}")
            request.state.user = user
            request.state.db = db

        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Auth error: {str(e)}")
            logger.error(traceback.format_exc())
            raise HTTPException(status_code=401, detail="Authentication failed")


class RateLimitMiddleware:
    """Rate limiting middleware to control API access"""

    async def __call__(self, request: Request):
        """Check if user has exceeded their rate limits"""
        try:
            # Skip rate limiting for auth routes
            if request.url.path.startswith("/api/v1/auth"):
                return

            user = request.state.user

            # Check monthly search limits
            if user.monthly_search_limit != -1:  # -1 means unlimited
                if user.monthly_searches >= user.monthly_search_limit:
                    raise HTTPException(
                        status_code=429,
                        detail="Monthly search limit exceeded"
                    )

            # Update search counters if this is a search request
            if request.url.path.endswith("/search"):
                user.monthly_searches += 1
                user.total_searches += 1
                request.state.db.commit()

        except Exception as e:
            logger.error(f"Rate limit error: {str(e)}")
            raise HTTPException(status_code=429, detail="Rate limit error")

================
File: schemas/auth/auth_schema.py
================
from pydantic import BaseModel, EmailStr
from typing import Optional


class UserResponse(BaseModel):
    id: int
    email: str
    name: Optional[str]
    subscription_tier: str
    is_active: bool

    class Config:
        from_attributes = True


class Token(BaseModel):
    access_token: str
    token_type: str
    refresh_token: Optional[str] = None


class TokenPayload(BaseModel):
    sub: Optional[str] = None


class UserCreate(BaseModel):
    email: EmailStr
    password: str
    name: Optional[str] = None

================
File: scripts/import_data.py
================
import pandas as pd
from sqlalchemy.orm import Session
from sqlalchemy.dialects.postgresql import insert
from database import engine
from models import Base, Investor, InvestmentFund
from typing import Type, Union
import logging
import os
import traceback

# Get the absolute path of the project root directory
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

Base.metadata.create_all(bind=engine)

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def get_column_mappings(model):
    if model == InvestmentFund:
        return {
            'Full Name': 'full_name',
            'Title': 'title',
            'Contact Email': 'contact_email',
            'Contact Phone': 'contact_phone',
            'Firm Name': 'firm_name',
            'Firm Email': 'firm_email',
            'Firm Phone': 'firm_phone',
            'Firm Website': 'firm_website',
            'Firm Address': 'firm_address',
            'Firm City': 'firm_city',
            'Firm State': 'firm_state',
            'Firm Zip': 'firm_zip',
            'Firm Country': 'firm_country',
            'Office Type': 'office_type',
            'Financing Type': 'financing_type',
            'Industry Preferences': 'industry_preferences',
            'Geographic Preferences': 'geographic_preferences',
            'Stage Preferences': 'stage_preferences',
            'Capital Managed': 'capital_managed',
            'Min. Investment': 'min_investment',
            'Max. Investment': 'max_investment',
            'Firm Type': 'firm_type'
        }
    else:  # Investor
        return {
            'Prefix': 'prefix',
            'First Name': 'first_name',
            'Last Name': 'last_name',
            'Gender': 'gender',
            'Contact Title': 'contact_title',
            'Email': 'email',
            'Phone': 'phone',
            'Office Website': 'office_website',
            'Firm Name': 'firm_name',
            'City': 'city',
            'Country': 'country',
            'Type of Financing': 'type_of_financing',
            'Industry Preferences': 'industry_preferences',
            'Geographic Preferences': 'geographic_preferences',
            'Stage Preferences': 'stage_preferences',
            'Capital Managed': 'capital_managed',
            'Min Investment': 'min_investment',
            'Max Investment': 'max_investment'
        }


def clean_and_convert_data(df: pd.DataFrame, model: Type[Union[Investor, InvestmentFund]]) -> pd.DataFrame:
    logger.info("\nStarting data cleaning and conversion")

    def convert_currency(value):
        if pd.isna(value) or value is None or value == '':
            return None
        try:
            # If value is already a number, return it
            if isinstance(value, (int, float)):
                return float(value) if value != 0 else None

            # If it's a string, clean and convert
            if isinstance(value, str):
                # Handle lists stored as strings
                if value.startswith('[') and value.endswith(']'):
                    return None
                # Remove any non-numeric characters except dots
                value_str = ''.join(c for c in value if c.isdigit() or c == '.')
                if value_str:
                    result = float(value_str)
                    return result if result != 0 else None
            return None
        except Exception as e:
            logger.error(f"Error converting value '{value}' ({type(value)}): {str(e)}")
            return None

    def convert_list_field(value):
        if pd.isna(value) or value is None or value == '':
            return None
        try:
            if isinstance(value, str):
                # If it's already in list format, try to evaluate it
                if value.startswith('[') and value.endswith(']'):
                    try:
                        # Clean the string before eval
                        cleaned_value = value.replace('", "', '","').strip()
                        result = eval(cleaned_value)
                        return result if result else None
                    except:
                        # If eval fails, split by comma
                        value = value.strip('[]')
                        if value:
                            return [item.strip().strip('"\'') for item in value.split(',') if item.strip()]
                        return None
                # Otherwise split by comma
                return [item.strip() for item in value.split(',') if item.strip()]
            elif isinstance(value, list):
                return value
            return None
        except Exception as e:
            logger.error(f"Error converting list value '{value}' ({type(value)}): {str(e)}")
            return None

    # Replace 'Unknown' and empty strings with None
    df = df.replace({'Unknown': None, '': None, 'N/A': None})

    # Convert numeric fields
    numeric_cols = ['min_investment', 'max_investment', 'capital_managed']

    # Process each numeric column
    for col in numeric_cols:
        if col in df.columns:
            logger.info(f"\nProcessing column: {col}")
            logger.info(f"Original values (first 5):\n{df[col].head()}")

            # Convert to numeric
            df[col] = df[col].apply(convert_currency)

            logger.info(f"Converted values (first 5):\n{df[col].head()}")
            non_null_count = df[col].notnull().sum()
            logger.info(f"Number of non-null values: {non_null_count}")

    # Handle list fields
    list_fields = ['industry_preferences', 'geographic_preferences', 'stage_preferences']
    if model == Investor:
        list_fields.append('type_of_financing')

    for field in list_fields:
        if field in df.columns:
            logger.info(f"\nProcessing list field: {field}")
            logger.info(f"Original values (first 5):\n{df[field].head()}")

            df[field] = df[field].apply(convert_list_field)

            logger.info(f"Converted values (first 5):\n{df[field].head()}")
            non_null_count = df[field].notnull().sum()
            logger.info(f"Number of non-null values: {non_null_count}")

    return df


def import_investors(csv_file: str, session: Session):
    logger.info("\nProcessing Investors data...")
    df = pd.read_csv(csv_file)

    # Print column info
    logger.info(f"Columns in CSV: {df.columns.tolist()}")
    logger.info("\nSample of numeric columns before processing:")
    for col in ['Min Investment', 'Max Investment', 'Capital Managed']:
        if col in df.columns:
            logger.info(f"\n{col}:")
            logger.info(df[col].head())

    # Rename columns
    df = df.rename(columns=get_column_mappings(Investor))

    df_cleaned = clean_and_convert_data(df, Investor)

    # Process in chunks
    chunk_size = 1000
    records_processed = 0

    for start_idx in range(0, len(df_cleaned), chunk_size):
        chunk = df_cleaned.iloc[start_idx:start_idx + chunk_size]

        for _, row in chunk.iterrows():
            try:
                # Convert row to dict and remove None values
                record = {k: v for k, v in row.items() if v is not None and k in Investor.__table__.columns.keys()}

                # Create an UPSERT statement
                stmt = insert(Investor).values(**record)
                stmt = stmt.on_conflict_do_update(
                    index_elements=['email'],
                    set_=record
                )
                session.execute(stmt)
                session.commit()
                records_processed += 1

            except Exception as e:
                logger.error(f"Error inserting investor record: {str(e)}")
                logger.error(f"Problematic record: {record}")
                session.rollback()

            if records_processed % 100 == 0:
                logger.info(f"Processed {records_processed} investor records")

        logger.info(f"Processed {records_processed} investor records in current chunk")

    logger.info(f"Total investors processed: {records_processed}")
    return records_processed


def import_investment_funds(csv_file: str, session: Session):
    logger.info("\nProcessing Investment Funds data...")
    df = pd.read_csv(csv_file)

    # Rename columns
    df = df.rename(columns=get_column_mappings(InvestmentFund))

    df_cleaned = clean_and_convert_data(df, InvestmentFund)

    # Process in chunks
    chunk_size = 1000
    records_processed = 0

    for start_idx in range(0, len(df_cleaned), chunk_size):
        chunk = df_cleaned.iloc[start_idx:start_idx + chunk_size]

        for _, row in chunk.iterrows():
            try:
                # Convert row to dict and remove None values
                record = {k: v for k, v in row.items() if
                          v is not None and k in InvestmentFund.__table__.columns.keys()}

                # Create an UPSERT statement
                stmt = insert(InvestmentFund).values(**record)
                stmt = stmt.on_conflict_do_update(
                    index_elements=['firm_email'],
                    set_=record
                )
                session.execute(stmt)
                session.commit()
                records_processed += 1

            except Exception as e:
                logger.error(f"Error inserting fund record: {str(e)}")
                logger.error(f"Problematic record: {record}")
                session.rollback()

        logger.info(f"Processed {records_processed} investment fund records")

    return records_processed


def main():
    try:
        with Session(engine) as session:
            # Import Investors
            investors_csv = os.path.join(BASE_DIR, 'data', 'investors_cleaned.csv')
            if os.path.exists(investors_csv):
                total_investors = import_investors(investors_csv, session)

                # Verify investors import
                total_count = session.query(Investor).count()
                logger.info(f"\nTotal investors in database: {total_count}")

                for col in ['min_investment', 'max_investment', 'capital_managed']:
                    count = session.query(Investor).filter(getattr(Investor, col).isnot(None)).count()
                    logger.info(f"Count of non-null values in {col}: {count}")

                    # Show sample values
                    samples = session.query(Investor).filter(getattr(Investor, col).isnot(None)).limit(3).all()
                    if samples:
                        logger.info(f"Sample values for {col}:")
                        for sample in samples:
                            logger.info(f"{getattr(sample, col)}")
            else:
                logger.warning(f"Investors CSV file not found: {investors_csv}")

            # Import Investment Funds
            funds_csv = os.path.join(BASE_DIR, 'data', 'vc_funds.csv')
            if os.path.exists(funds_csv):
                total_funds = import_investment_funds(funds_csv, session)

                # Verify investment funds import
                total_count = session.query(InvestmentFund).count()
                logger.info(f"\nTotal investment funds in database: {total_count}")

                for col in ['min_investment', 'max_investment', 'capital_managed']:
                    count = session.query(InvestmentFund).filter(getattr(InvestmentFund, col).isnot(None)).count()
                    logger.info(f"Count of non-null values in {col}: {count}")

                    # Show sample values
                    samples = session.query(InvestmentFund).filter(getattr(InvestmentFund, col).isnot(None)).limit(
                        3).all()
                    if samples:
                        logger.info(f"Sample values for {col}:")
                        for sample in samples:
                            logger.info(f"{getattr(sample, col)}")
            else:
                logger.warning(f"Investment Funds CSV file not found: {funds_csv}")

    except Exception as e:
        logger.error(f"An error occurred: {str(e)}")
        traceback.print_exc()


if __name__ == "__main__":
    main()

================
File: scripts/reset_database.py
================
from sqlalchemy import create_engine, inspect
from database import SQLALCHEMY_DATABASE_URL
from models import Base


def reset_database():
    engine = create_engine(SQLALCHEMY_DATABASE_URL)
    inspector = inspect(engine)

    # Get list of all table names
    table_names = inspector.get_table_names()

    # Drop all tables
    Base.metadata.drop_all(bind=engine)
    print(f"Dropped tables: {', '.join(table_names)}")

    # Recreate all tables
    Base.metadata.create_all(bind=engine)
    print("Recreated all tables.")


if __name__ == "__main__":
    reset_database()

================
File: scripts/update_schema.py
================
from sqlalchemy import create_engine
from database import SQLALCHEMY_DATABASE_URL
from models import Base


def update_schema():
    engine = create_engine(SQLALCHEMY_DATABASE_URL)

    # This will create tables that don't exist, but won't modify existing tables
    Base.metadata.create_all(bind=engine)

    print("Database schema updated.")


if __name__ == "__main__":
    update_schema()

================
File: services/investor_service.py
================
from sqlalchemy.orm import Session
from models import Investor
from schemas import investors as schemas


def create_investor(db: Session, investor: schemas.InvestorCreate):
    db_investor = Investor(**investor.model_dump())
    db.add(db_investor)
    db.commit()
    db.refresh(db_investor)
    return db_investor


def search_investors(db: Session, filters):
    query = db.query(Investor)
    # Apply filters
    return query.all()

================
File: app.py
================
from fastapi import FastAPI, Depends
from fastapi.middleware.cors import CORSMiddleware
from api.v1.endpoints import (
    investors,
    investment_funds,
    users,
    export,
    utils,
    auth
)
from database import engine, get_db, test_db_connection
from middleware.auth import AuthMiddleware, RateLimitMiddleware
import models
import os
import logging
import sys
from datetime import datetime


# Configure logging
def setup_logging():
    # Create logs directory if it doesn't exist
    from pathlib import Path
    Path("logs").mkdir(exist_ok=True)

    # Configure logging format
    log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    formatter = logging.Formatter(log_format)

    # Set up file handler
    file_handler = logging.FileHandler(
        f'logs/app_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'
    )
    file_handler.setFormatter(formatter)

    # Set up console handler
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)

    # Configure root logger
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)
    root_logger.addHandler(file_handler)
    root_logger.addHandler(console_handler)

    return root_logger


logger = setup_logging()

# Create FastAPI app
app = FastAPI(
    title="Investor Database API",
    description="API for managing investors and investment funds database",
    version="1.0.0"
)


# Test database connection on startup
@app.on_event("startup")
async def startup_event():
    """Run startup tasks"""
    logger.info("Starting up...")
    if not test_db_connection():
        logger.error("Database connection failed!")
        # In production, you might want to exit here
        # import sys; sys.exit(1)


# Configure CORS
origins = os.getenv("ALLOWED_ORIGINS", "http://localhost:3000").split(",")
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Auth dependencies
auth_middleware = AuthMiddleware()
rate_limit_middleware = RateLimitMiddleware()


def get_auth_dependencies():
    """Get all auth dependencies"""
    return [
        Depends(get_db),
        Depends(auth_middleware),
        Depends(rate_limit_middleware)
    ]


# Public routes - no auth required
public_routes = [
    (auth.router, "/api/v1/auth", "auth"),
    (utils.router, "/api/v1", "utils")
]

for router, prefix, tag in public_routes:
    app.include_router(router, prefix=prefix, tags=[tag])

# Protected routes - require auth & respect rate limits
protected_routes = [
    (investors.router, "/api/v1/investors", "investors"),
    (investment_funds.router, "/api/v1/funds", "funds"),
    (export.router, "/api/v1/export", "export"),
    (users.router, "/api/v1/users", "users"),
]

for router, prefix, tag in protected_routes:
    app.include_router(
        router,
        prefix=prefix,
        tags=[tag],
        dependencies=get_auth_dependencies()
    )


@app.get("/health")
async def health_check():
    """API health check endpoint"""
    return {
        "status": "healthy",
        "version": "1.0.0",
        "environment": os.getenv("ENVIRONMENT", "development"),
        "database": "connected" if test_db_connection() else "error"
    }

================
File: crud.py
================
from sqlalchemy.orm import Session
from sqlalchemy import Column, or_, String, Text
from sqlalchemy.sql import expression
import models
import schemas
from typing import TypeVar, Generic, List, Any, Dict, Optional, Type, Union
from sqlalchemy.exc import SQLAlchemyError
import logging
import math
from decimal import Decimal

ModelType = TypeVar("ModelType", bound=models.Base)
CreateSchemaType = TypeVar("CreateSchemaType", bound=schemas.BaseModel)

logger = logging.getLogger(__name__)


class CRUDBase(Generic[ModelType, CreateSchemaType]):
    def __init__(self, model: Type[ModelType]):
        self.model = model

    def get_multi(
            self,
            db: Session,
            skip: int = 0,
            limit: int = 100,
            search: Optional[str] = None,
            filters: Optional[Dict] = None,
            sort_by: Optional[str] = None,
            sort_desc: bool = False
    ) -> List[Dict]:
        try:
            query = db.query(self.model)

            # Apply text search across string fields
            if search:
                search_filters = []
                for column in self.model.__table__.columns:
                    if isinstance(column.type, (String, Text)):
                        search_filters.append(getattr(self.model, column.key).ilike(f"%{search}%"))
                if search_filters:
                    query = query.filter(or_(*search_filters))

            # Apply filters
            if filters:
                for key, value in filters.items():
                    if hasattr(self.model, key):
                        if isinstance(value, dict):
                            col = getattr(self.model, key)
                            for op, val in value.items():
                                if op == "gte":
                                    query = query.filter(col >= val)
                                elif op == "lte":
                                    query = query.filter(col <= val)
                        elif isinstance(value, (list, tuple)):
                            # Handle array overlaps for preferences
                            col = getattr(self.model, key)
                            if hasattr(col, 'overlap'):
                                query = query.filter(col.overlap(value))
                            else:
                                query = query.filter(col.in_(value))
                        else:
                            query = query.filter(getattr(self.model, key) == value)

            # Apply sorting
            if sort_by and hasattr(self.model, sort_by):
                order_col = getattr(self.model, sort_by)
                if sort_desc:
                    order_col = order_col.desc()
                query = query.order_by(order_col)

            records = query.offset(skip).limit(limit).all()
            return [self.to_dict(record) for record in records]

        except Exception as e:
            logger.error(f"Error in get_multi: {str(e)}")
            raise

    @staticmethod
    def sanitize_float(value: Any) -> Optional[float]:
        if value is None:
            return None
        if isinstance(value, (float, Decimal)):
            if math.isnan(float(value)) or math.isinf(float(value)):
                return None
            return float(value)
        return value

    @staticmethod
    def sanitize_list(value: Any) -> Optional[List]:
        if value is None:
            return None
        if isinstance(value, list):
            return [str(item) for item in value if item is not None]
        if isinstance(value, str):
            return [value]
        return None

    def to_dict(self, obj: ModelType) -> Dict:
        result = {}
        for column in obj.__table__.columns:
            value = getattr(obj, column.name)

            # Handle different types of values
            if isinstance(value, (float, Decimal)):
                # Handle non-JSON-compliant float values
                if value is None or math.isnan(float(value)) or math.isinf(float(value)):
                    result[column.name] = None
                else:
                    result[column.name] = float(value)
            elif isinstance(value, list):
                # Handle lists (like arrays from postgres)
                if value and isinstance(value[0], str) and value[0].startswith('{'):
                    # Handle PostgreSQL array format {item1,item2}
                    cleaned = value[0].strip('{}').split(',')
                    result[column.name] = [item.strip('"') for item in cleaned if item]
                else:
                    result[column.name] = value
            else:
                result[column.name] = value

        return result

    def create(self, db: Session, obj_in: CreateSchemaType) -> Dict:
        try:
            obj_in_data = self.prepare_data_for_db(obj_in.model_dump())
            db_obj = self.model(**obj_in_data)
            db.add(db_obj)
            db.commit()
            db.refresh(db_obj)
            return self.to_dict(db_obj)
        except Exception as e:
            db.rollback()
            logger.error(f"Error creating {self.model.__name__}: {str(e)}")
            raise

    def get(self, db: Session, id: Any) -> Optional[ModelType]:
        try:
            obj = db.query(self.model).filter(self.model.id == id).first()
            if obj:
                return self.to_dict(obj)
            return None
        except Exception as e:
            logger.error(f"Error in get: {str(e)}")
            raise

    def update(self, db: Session, id: Any, obj_in: CreateSchemaType) -> Optional[Dict]:
        try:
            db_obj = db.query(self.model).filter(self.model.id == id).first()
            if db_obj:
                obj_data = self.prepare_data_for_db(obj_in.model_dump(exclude_unset=True))
                for key, value in obj_data.items():
                    setattr(db_obj, key, value)

                db.commit()
                db.refresh(db_obj)
                return self.to_dict(db_obj)
            return None
        except Exception as e:
            db.rollback()
            logger.error(f"Error updating {self.model.__name__}: {str(e)}")
            raise

    def delete(self, db: Session, id: Any) -> Optional[Dict]:
        try:
            obj = db.query(self.model).get(id)

            if obj:
                obj_dict = self.to_dict(obj)
                db.delete(obj)
                db.commit()
                return obj_dict
            return None
        except Exception as e:
            db.rollback()
            logger.error(f"Error deleting {self.model.__name__}: {str(e)}")
            raise

    @staticmethod
    def handle_float(value: Any) -> Optional[float]:
        if value is None:
            return None
        if isinstance(value, (float, Decimal)):
            try:
                float_val = float(value)
                if math.isnan(float_val) or math.isinf(float_val):
                    return None
                return float_val
            except (ValueError, TypeError):
                return None
        return value

    def prepare_data_for_db(self, data: Dict[str, Any]) -> Dict[str, Any]:
        prepared_data = {}
        for key, value in data.items():
            if isinstance(value, (float, Decimal)):
                prepared_data[key] = self.handle_float(value)
            elif isinstance(value, list):
                prepared_data[key] = [str(item) for item in value if item] or None
            else:
                prepared_data[key] = value
        return prepared_data


class CRUDInvestor(CRUDBase[models.Investor, schemas.InvestorCreate]):
    def get_by_email(self, db: Session, email: str) -> Optional[models.Investor]:
        return db.query(models.Investor).filter(models.Investor.email == email).first()

    def get_by_industry(self, db: Session, industry: str) -> List[models.Investor]:
        return db.query(models.Investor).filter(
            models.Investor.industry_preferences.overlap([industry])
        ).all()


class CRUDInvestmentFund(CRUDBase[models.InvestmentFund, schemas.InvestmentFundCreate]):
    def get_by_firm_email(self, db: Session, firm_email: str) -> Optional[models.InvestmentFund]:
        return db.query(models.InvestmentFund).filter(
            models.InvestmentFund.firm_email == firm_email
        ).first()

    def get_by_firm_name(self, db: Session, firm_name: str) -> Optional[models.InvestmentFund]:
        return db.query(models.InvestmentFund).filter(
            models.InvestmentFund.firm_name == firm_name
        ).first()


# Create instances
investor = CRUDInvestor(models.Investor)
investment_fund = CRUDInvestmentFund(models.InvestmentFund)

================
File: database.py
================
# database.py
from sqlalchemy import create_engine, text
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import os
from dotenv import load_dotenv
import logging
import traceback

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Get database URL from environment variables with fallback
SQLALCHEMY_DATABASE_URL = os.getenv(
    "DATABASE_URL",
    "postgresql://investor_admin:your_secure_password@localhost/investor_db"
)

# Create engine with proper configuration
engine = create_engine(
    SQLALCHEMY_DATABASE_URL,
    pool_pre_ping=True,  # Enable connection health checks
    pool_size=5,  # Maximum number of database connections in the pool
    max_overflow=10  # Maximum number of connections that can be created beyond pool_size
)

# Create SessionLocal class with proper configuration
SessionLocal = sessionmaker(
    autocommit=False,
    autoflush=False,
    bind=engine,
    expire_on_commit=False
)

# Create Base class for declarative models
Base = declarative_base()


def get_db():
    """Dependency that provides a database session"""
    db = SessionLocal()
    try:
        logger.debug("Creating new database session")
        yield db
    except Exception as e:
        logger.error(f"Database session error: {str(e)}")
        logger.error(traceback.format_exc())
        raise
    finally:
        logger.debug("Closing database session")
        db.close()

def test_db_connection():
    """Test database connection"""
    try:
        logger.info("Testing database connection...")
        db = SessionLocal()
        db.execute(text("SELECT 1"))
        db.close()
        logger.info("Database connection successful!")
        return True
    except Exception as e:
        logger.error(f"Database connection failed: {str(e)}")
        logger.error(traceback.format_exc())
        return False

================
File: models.py
================
from sqlalchemy import Column, Integer, String, Float, ARRAY, Text, DateTime, Boolean, ForeignKey
from sqlalchemy.dialects.postgresql import ARRAY as PG_ARRAY
from sqlalchemy.sql import func
from database import Base


class User(Base):
    __tablename__ = "users"

    id = Column(Integer, primary_key=True, index=True)
    email = Column(String, unique=True, index=True)
    name = Column(String, nullable=True)
    subscription_tier = Column(String, default="free")  # free, basic, professional
    subscription_status = Column(String, default="active")
    subscription_start = Column(DateTime(timezone=True), server_default=func.now())
    subscription_end = Column(DateTime(timezone=True), nullable=True)

    # Usage tracking
    monthly_searches = Column(Integer, default=0)
    last_search = Column(DateTime(timezone=True), nullable=True)
    total_searches = Column(Integer, default=0)

    # Feature access flags
    can_export = Column(Boolean, default=False)
    can_see_full_profiles = Column(Boolean, default=False)
    can_see_contact_info = Column(Boolean, default=False)
    monthly_search_limit = Column(Integer, default=10)  # -1 for unlimited

    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())


class Investor(Base):
    __tablename__ = "investors"

    id = Column(Integer, primary_key=True, index=True)
    prefix = Column(String, nullable=True)
    first_name = Column(String)
    last_name = Column(String)
    gender = Column(String, nullable=True)
    contact_title = Column(String, nullable=True)
    email = Column(String, unique=True, index=True)
    phone = Column(String, nullable=True)
    office_website = Column(String, nullable=True)
    firm_name = Column(String, nullable=True)
    city = Column(String, nullable=True)
    state = Column(String, nullable=True)
    country = Column(String, nullable=True)
    type_of_financing = Column(String, nullable=True)
    industry_preferences = Column(PG_ARRAY(String), nullable=True)
    geographic_preferences = Column(PG_ARRAY(String), nullable=True)
    stage_preferences = Column(PG_ARRAY(String), nullable=True)
    capital_managed = Column(Float, nullable=True)
    min_investment = Column(Float, nullable=True)
    max_investment = Column(Float, nullable=True)


class InvestmentFund(Base):
    __tablename__ = "investment_funds"

    id = Column(Integer, primary_key=True, index=True)
    full_name = Column(String)
    title = Column(String, nullable=True)
    contact_email = Column(String, index=True)
    contact_phone = Column(String, nullable=True)
    firm_name = Column(String)
    firm_email = Column(String, unique=True, index=True, nullable=True)
    firm_phone = Column(String, nullable=True)
    firm_website = Column(String, nullable=True)
    firm_address = Column(String, nullable=True)
    firm_city = Column(String, nullable=True)
    firm_state = Column(String, nullable=True)
    firm_zip = Column(String, nullable=True)
    firm_country = Column(String, nullable=True)
    office_type = Column(String, nullable=True)
    financing_type = Column(String, nullable=True)
    industry_preferences = Column(PG_ARRAY(String), nullable=True)
    geographic_preferences = Column(PG_ARRAY(String), nullable=True)
    stage_preferences = Column(PG_ARRAY(String), nullable=True)
    capital_managed = Column(Float, nullable=True)
    min_investment = Column(Float, nullable=True)
    max_investment = Column(Float, nullable=True)
    firm_type = Column(String, nullable=True)
    description = Column(Text, nullable=True)

================
File: requirements.txt
================
fastapi
uvicorn[standard]==0.24.0
sqlalchemy
psycopg2-binary==2.9.9
pydantic
python-dotenv==1.0.0
typing-extensions==4.8.0
email-validator==2.1.0.post1
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4
python-multipart==0.0.18
alembic
pytest==7.4.3
httpx==0.25.1
pandas~=2.2.3
PyJWT

================
File: schemas.py
================
from typing import List, Optional
from pydantic import BaseModel, ConfigDict
from enum import Enum


# ==================== Enums ====================

class City(str, Enum):
    NEW_YORK = "New York"
    LONDON = "London"
    SAN_FRANCISCO = "San Francisco"
    CHICAGO = "Chicago"
    BOSTON = "Boston"
    PARIS = "Paris"
    TORONTO = "Toronto"
    PALO_ALTO = "Palo Alto"
    SHANGHAI = "Shanghai"
    TOKYO = "Tokyo"
    BEIJING = "Beijing"
    MUMBAI = "Mumbai"
    CAMBRIDGE = "Cambridge"
    AUSTIN = "Austin"


class State(str, Enum):
    CALIFORNIA = "California"
    NEW_YORK = "New York"
    MASSACHUSETTS = "Massachusetts"
    TEXAS = "Texas"
    ILLINOIS = "Illinois"
    ONTARIO = "Ontario"
    CONNECTICUT = "Connecticut"
    FLORIDA = "Florida"
    PENNSYLVANIA = "Pennsylvania"
    COLORADO = "Colorado"
    MICHIGAN = "Michigan"
    OHIO = "Ohio"
    GEORGIA = "Georgia"
    MARYLAND = "Maryland"
    VIRGINIA = "Virginia"
    NEW_SOUTH_WALES = "New South Wales"
    NORTH_CAROLINA = "North Carolina"
    WASHINGTON = "Washington"
    BRITISH_COLUMBIA = "British Columbia"
    NEW_JERSEY = "New Jersey"


class Country(str, Enum):
    UNITED_STATES = "United States"
    UNITED_KINGDOM = "United Kingdom"
    GERMANY = "Germany"
    CANADA = "Canada"
    CHINA = "China"
    FRANCE = "France"
    INDIA = "India"
    ISRAEL = "Israel"
    HONG_KONG = "Hong Kong"
    JAPAN = "Japan"
    SINGAPORE = "Singapore"
    SWEDEN = "Sweden"
    AUSTRALIA = "Australia"
    NETHERLANDS = "Netherlands"
    SPAIN = "Spain"
    BELGIUM = "Belgium"
    SWITZERLAND = "Switzerland"
    FINLAND = "Finland"
    ITALY = "Italy"
    KOREA = "Korea"


class LocationPreference(str, Enum):
    UNITED_STATES = "United States"
    EUROPE = "Europe"
    CANADA = "Canada"
    UNITED_KINGDOM = "United Kingdom"
    CHINA = "China"
    GERMANY = "Germany"
    UNITED_STATES_CALIFORNIA = "United States (California)"
    ASIA = "Asia"
    FRANCE = "France"
    UNITED_STATES_MID_ATLANTIC = "United States (Mid-Atlantic)"
    UNITED_STATES_MIDWEST = "United States (Midwest)"
    UNITED_STATES_SOUTHEAST = "United States (Southeast)"
    UNITED_STATES_SOUTHWEST = "United States (Southwest)"
    UNITED_STATES_NORTHEAST = "United States (Northeast)"
    NETHERLANDS = "Netherlands"
    SWITZERLAND = "Switzerland"
    SWEDEN = "Sweden"
    INDIA = "India"
    AUSTRALIA = "Australia"


class IndustryPreference(str, Enum):
    IT_SERVICES = "IT Services"
    COMMUNICATIONS_NETWORKING = "Communications & Networking"
    SOFTWARE = "Software"
    HEALTHCARE_SERVICES = "Healthcare Services"
    CONSUMER_PRODUCTS_SERVICES = "Consumer Products & Services"
    BUSINESS_PRODUCTS_SERVICES = "Business Products & Services"
    MEDIA_ENTERTAINMENT = "Media & Entertainment"
    DISTRIBUTION_RETAIL = "Distribution/Retailing"
    FINANCIAL_SERVICES = "Financial Services"
    NATURAL_RESOURCES = "Natural Resources"
    DIVERSIFIED = "Diversified"
    INTERNET_TECHNOLOGY = "Internet Technology"
    CHEMICALS_MATERIALS = "Chemicals & Materials"
    MANUFACTURING = "Manufacturing"
    BIOTECHNOLOGY = "Biotechnology"
    ELECTRONICS = "Electronics"
    MEDICAL_DEVICES = "Medical Devices & Equipment"
    INDUSTRIAL_PRODUCTS = "Industrial Products & Services"
    FOOD_SERVICES = "Food Services & Products"
    ENVIRONMENT = "Environment"


class FundType(str, Enum):
    PRIVATE_EQUITY = "Private Equity Fund"
    VENTURE_CAPITAL = "Venture Capital Fund"
    INVESTMENT_BANK = "Investment Bank"
    SMALL_BUSINESS = "Small Business Investment Company"
    STARTUP_STUDIO = "Startup Studio"
    GOVERNMENT = "Government Organization"


class StagePreference(str, Enum):
    EXPANSION = "Expansion"
    MBO_LBO = "MBO/LBO"
    EARLY_STAGE = "Early Stage"
    STARTUP = "Startup"
    SEED = "Seed"
    ACQUISITION = "Acquisition"
    RECAPITALIZATION = "Recapitalization"
    LATER_STAGE = "Later Stage"
    RESTRUCTURING = "Restructuring"
    CORPORATE_DIVESTITURE = "Corporate Divestiture"
    CONSOLIDATION = "Consolidation"
    GOING_PRIVATE = "Going Private"
    SPECIAL_SITUATIONS = "Special Situations"
    TURNAROUND = "Turnaround"
    PIPE = "PIPE"
    SPINOUT = "Spinout"
    SECONDARY_PURCHASE = "Secondary Purchase"
    OWNERSHIP_TRANSITION = "Ownership Transition"
    DISTRESSED_DEBT = "Distressed Debt"
    PRIVATIZATION = "Privatization"


class AssetsUnderManagement(str, Enum):
    TIER_1B_PLUS = "$1B+"
    TIER_100M_500M = "$100M-$500M"
    TIER_500M_1B = "$500M-$1B"
    TIER_25M_100M = "$25M-$100M"
    TIER_0_25M = "$0-$25M"


class MinInvestment(str, Enum):
    TIER_25K_250K = "$25K-$250K"
    TIER_250K_1M = "$250K-$1M"
    TIER_1M_5M = "$1M-$5M"
    TIER_5M_PLUS = "$5M+"
    TIER_0_25K = "$0-$25K"


class MaxInvestment(str, Enum):
    TIER_25M_150M = "$25M-$150M"
    TIER_10M_25M = "$10M-$25M"
    TIER_1M_10M = "$1M-$10M"
    TIER_150M_PLUS = "$150M+"
    TIER_0_1M = "$0-$1M"


class NumberOfInvestors(str, Enum):
    TIER_1_10 = "1-10"
    TIER_11_20 = "11-20"
    TIER_21_30 = "21-30"
    TIER_31_40 = "31-40"


class GenderRatio(str, Enum):
    NO_FEMALE = "0% Female"
    FEMALE_25 = "25% Female"
    FEMALE_33 = "33% Female"
    FEMALE_50 = "50% Female"
    FEMALE_67 = "67% Female"
    FEMALE_75 = "75% Female"
    FEMALE_100 = "100% Female"


# ==================== Filter Models ====================

class LocationFilter(BaseModel):
    city: Optional[List[str]] = None
    state: Optional[List[str]] = None
    country: Optional[List[str]] = None
    location_preferences: Optional[List[str]] = None


class ContactAvailabilityFilter(BaseModel):
    hasOfficeEmail: Optional[bool] = None
    hasOfficePhone: Optional[bool] = None
    hasOfficeAddress: Optional[bool] = None


class IndustryFilter(BaseModel):
    industries: Optional[List[str]] = None


class StagePreferencesFilter(BaseModel):
    stages: Optional[List[str]] = None


class FundTypeFilter(BaseModel):
    types: Optional[List[str]] = None


class InvestmentRangesFilter(BaseModel):
    assetsUnderManagement: Optional[str] = None
    minInvestment: Optional[str] = None
    maxInvestment: Optional[str] = None


class InvestorCountFilter(BaseModel):
    range: Optional[str] = None


class GenderRatioFilter(BaseModel):
    ratio: Optional[str] = None


class GenderFilter(BaseModel):
    gender: Optional[str] = None


class FirmFilter(BaseModel):
    names: Optional[List[str]] = None


class JobTitleFilter(BaseModel):
    titles: Optional[List[str]] = None


class ContactInfoFilter(BaseModel):
    hasEmail: Optional[bool] = None
    hasPhone: Optional[bool] = None
    hasAddress: Optional[bool] = None


# ==================== Base Models ====================

class InvestorBase(BaseModel):
    prefix: Optional[str] = None
    first_name: Optional[str] = None
    last_name: Optional[str] = None
    gender: Optional[str] = None
    contact_title: Optional[str] = None
    email: Optional[str] = None
    phone: Optional[str] = None
    office_email: Optional[str] = None
    office_phone: Optional[str] = None
    office_website: Optional[str] = None
    office_address: Optional[str] = None
    firm_name: Optional[str] = None
    city: Optional[str] = None
    state: Optional[str] = None
    country: Optional[str] = None
    type_of_financing: Optional[str] = None
    industry_preferences: Optional[List[str]] = None
    geographic_preferences: Optional[List[str]] = None
    stage_preferences: Optional[List[str]] = None
    capital_managed: Optional[float] = None
    min_investment: Optional[float] = None
    max_investment: Optional[float] = None
    assets_under_management: Optional[float] = None
    number_of_investors: Optional[int] = None
    gender_ratio: Optional[str] = None


class InvestorCreate(InvestorBase):
    pass


class Investor(InvestorBase):
    id: int
    model_config = ConfigDict(from_attributes=True)


class InvestmentFundBase(BaseModel):
    full_name: str
    title: Optional[str] = None
    contact_email: str
    contact_phone: Optional[str] = None
    firm_name: str
    firm_email: Optional[str] = None
    firm_phone: Optional[str] = None
    firm_website: Optional[str] = None
    firm_address: Optional[str] = None
    firm_city: Optional[str] = None
    firm_state: Optional[str] = None
    firm_zip: Optional[str] = None
    firm_country: Optional[str] = None
    office_type: Optional[str] = None
    financing_type: Optional[str] = None
    industry_preferences: Optional[List[str]] = None
    geographic_preferences: Optional[List[str]] = None
    stage_preferences: Optional[List[str]] = None
    capital_managed: Optional[float] = None
    min_investment: Optional[float] = None
    max_investment: Optional[float] = None
    firm_type: Optional[str] = None
    description: Optional[str] = None
    number_of_investors: Optional[int] = None
    gender_ratio: Optional[str] = None
    assets_under_management: Optional[float] = None


class InvestmentFundCreate(InvestmentFundBase):
    pass


class InvestmentFund(InvestmentFundBase):
    id: int
    model_config = ConfigDict(
        from_attributes=True,
        json_encoders={float: lambda v: v if v is not None else None}
    )


# ==================== Filter Params ====================

class InvestorFilterParams(BaseModel):
    searchTerm: Optional[str] = None
    location: Optional[LocationFilter] = None
    contactInfo: Optional[ContactInfoFilter] = None
    industry: Optional[IndustryFilter] = None
    fundType: Optional[FundTypeFilter] = None  # Added
    stages: Optional[StagePreferencesFilter] = None
    investmentRanges: Optional[InvestmentRangesFilter] = None
    firm: Optional[FirmFilter] = None  # Added
    jobTitle: Optional[JobTitleFilter] = None  # Added
    investorCount: Optional[InvestorCountFilter] = None
    gender: Optional[GenderFilter] = None

    class Config:
        use_enum_values = True


class InvestmentFundFilterParams(BaseModel):
    searchTerm: Optional[str] = None
    location: Optional[LocationFilter] = None
    contactInfo: Optional[ContactInfoFilter] = None
    industry: Optional[IndustryFilter] = None
    fundType: Optional[FundTypeFilter] = None
    stages: Optional[StagePreferencesFilter] = None
    investmentRanges: Optional[InvestmentRangesFilter] = None
    investorCount: Optional[InvestorCountFilter] = None
    genderRatio: Optional[GenderRatioFilter] = None

    class Config:
        use_enum_values = True

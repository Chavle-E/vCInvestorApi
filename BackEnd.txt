This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-03-25T20:13:28.667Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
api/
  v1/
    endpoints/
      auth.py
      counts.py
      export.py
      fund_filters.py
      google_auth.py
      investment_funds.py
      investor_filters.py
      investors.py
      lists.py
      utils.py
    dependencies.py
middleware/
  auth_rate_limit.py
  rate_limit.py
scripts/
  cleanup_token.py
  import_data.py
  reset_database.py
  update_schema.py
  user_table.py
.gitignore
app.py
auth.py
crud.py
database.py
docker-compose.yml
Dockerfile
models.py
requirements.txt
schemas.py

================================================================
Repository Files
================================================================

================
File: api/v1/endpoints/auth.py
================
from fastapi import APIRouter, Depends, HTTPException, status, BackgroundTasks, Body
import asyncio
from sqlalchemy.orm import Session
from database import get_db
import models
import schemas
import logging
from datetime import datetime, timedelta, UTC
import auth
import bcrypt
from auth import verify_refresh_token, create_access_token, create_refresh_token, revoke_refresh_token

router = APIRouter()
logger = logging.getLogger(__name__)


async def send_verification_email(email: str, token: str):
    logger.info(f"Sending verification email to {email} with token {token}")


async def send_password_reset_email(email: str, token: str):
    logger.info(f"Sending password reset email to {email} with token {token}")


@router.post('/register', response_model=schemas.UserResponse)
async def register(
        user_in: schemas.UserCreate,
        background_tasks: BackgroundTasks,
        db: Session = Depends(get_db)
):
    db_user = db.query(models.User).filter(models.User.email == user_in.email).first()
    if db_user:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Email already registered"
        )

    verification_token = auth.generate_token()
    hashed_password = auth.get_password_hash(user_in.password)

    db_user = models.User(
        email=user_in.email,
        first_name=user_in.first_name,
        last_name=user_in.last_name,
        hashed_password=hashed_password,
        verification_token=verification_token,
        is_verified=False
    )

    db.add(db_user)
    db.commit()
    db.refresh(db_user)

    background_tasks.add_task(send_verification_email, user_in.email, verification_token)

    return db_user


@router.post("/login", response_model=schemas.Token)
async def login(
        credentials: schemas.UserLogin,
        db: Session = Depends(get_db)
):
    user = db.query(models.User).filter(models.User.email == credentials.email).first()
    if not user:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect email or password",
            headers={"WWW-Authenticate": "Bearer"},
        )

    # Convert password to bytes if it's a string
    pwd = credentials.password.encode('utf-8') if isinstance(credentials.password, str) else credentials.password
    hashed = user.hashed_password.encode('utf-8') if isinstance(user.hashed_password, str) else user.hashed_password

    if not bcrypt.checkpw(pwd, hashed):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect email or password",
            headers={"WWW-Authenticate": "Bearer"},
        )

    # Create access token
    access_token_expires = timedelta(minutes=auth.ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = auth.create_access_token(
        data={"sub": str(user.id)},
        expires_delta=access_token_expires
    )

    # Create refresh token
    refresh_token = auth.create_refresh_token(user_id=user.id, db=db)

    # Update last login time
    user.last_login = datetime.now(UTC)
    db.commit()

    return {
        "access_token": access_token,
        "token_type": "bearer",
        "refresh_token": refresh_token
    }


@router.post("/verify-email")
async def verify_email(
        verification: schemas.VerifyEmail,
        db: Session = Depends(get_db)
):
    user = db.query(models.User).filter(models.User.verification_token == verification.token).first()
    if not user:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Invalid verification token"
        )
    user.is_verified = True
    user.verification_token = None
    db.commit()

    return {"message": "Email verified successfully"}


@router.post("/forgot-password")
async def forgot_password(
        password_reset: schemas.PasswordReset,
        background_tasks: BackgroundTasks,
        db: Session = Depends(get_db)
):
    user = db.query(models.User).filter(models.User.email == password_reset.email).first()

    reset_token = auth.generate_token()
    reset_token_expires = datetime.now(UTC) + timedelta(hours=24)

    if user:
        user.reset_token = reset_token
        user.reset_token_expires = reset_token_expires
        db.commit()

        background_tasks.add_task(send_password_reset_email, user.email, reset_token)
    else:
        await asyncio.sleep(0.5)

    return {"message": "If this email is registered, a password reset link has been sent"}


@router.post("/reset-password")
async def reset_password(
        password_reset: schemas.PasswordResetConfirm,
        db: Session = Depends(get_db)
):
    if password_reset.new_password != password_reset.confirm_password:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Passwords do not match"
        )

    user = db.query(models.User).filter(models.User.reset_token == password_reset.token).first()
    if not user:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Invalid reset token"
        )

    if user.reset_token_expires < datetime.now(UTC):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Reset token has expired"
        )

    user.hashed_password = auth.get_password_hash(password_reset.new_password)
    user.reset_token = None
    user.reset_token_expires = None
    db.commit()

    return {"message": "Password reset successfully"}


@router.post("/change-password")
async def change_password(
        password_update: schemas.PasswordUpdate,
        current_user: models.User = Depends(auth.get_current_user),
        db: Session = Depends(get_db)
):
    if not auth.verify_password(password_update.current_password, current_user.hashed_password):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Incorrect current password"
        )

    if password_update.new_password != password_update.confirm_password:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Passwords do not match"
        )

    current_user.hashed_password = auth.get_password_hash(password_update.new_password)
    db.commit()

    return {"message": "Password changed successfully"}


@router.get("/me", response_model=schemas.UserResponse)
async def read_users_me(current_user: models.User = Depends(auth.get_current_user)):
    return current_user


@router.put("/me", response_model=schemas.UserResponse)
async def update_user(
        user_update: schemas.UserUpdate,
        current_user: models.User = Depends(auth.get_current_user),
        db: Session = Depends(get_db)
):
    if user_update.first_name is not None:
        current_user.first_name = user_update.first_name

    if user_update.last_name is not None:
        current_user.last_name = user_update.last_name

    if user_update.email is not None and user_update.email != current_user.email:
        # Check if email already exists
        existing_user = db.query(models.User).filter(models.User.email == user_update.email).first()
        if existing_user:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Email already registered"
            )

        current_user.email = user_update.email
        current_user.is_verified = False
        verification_token = auth.generate_token()
        current_user.verification_token = verification_token

    if user_update.profile_photo is not None:
        current_user.profile_photo = user_update.profile_photo

    db.commit()
    db.refresh(current_user)

    return current_user


@router.post("/deactivate")
async def deactivate_account(
        current_user: models.User = Depends(auth.get_current_user),
        db: Session = Depends(get_db)
):
    current_user.is_active = False
    db.commit()

    return {"message": "Account deactivated successfully"}


@router.post("/refresh", response_model=schemas.Token)
async def refresh_access_token(
        refresh_token: str = Body(..., embed=True),
        db: Session = Depends(get_db)
):
    user = verify_refresh_token(refresh_token, db)
    if not user:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid refresh token",
            headers={"WWW-Authenticate": "Bearer"},
        )

    # Create new access token
    access_token_expires = timedelta(minutes=auth.ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = create_access_token(
        data={"sub": str(user.id)},
        expires_delta=access_token_expires
    )

    # Create new refresh token (token rotation for better security)
    new_refresh_token = create_refresh_token(user_id=user.id, db=db)

    # Revoke the old refresh token
    revoke_refresh_token(refresh_token, db)

    return {
        "access_token": access_token,
        "token_type": "bearer",
        "refresh_token": new_refresh_token
    }


@router.post("/logout")
async def logout(
        refresh_token: str = Body(..., embed=True),
        db: Session = Depends(get_db)
):
    """Revoke refresh token on logout"""
    success = auth.revoke_refresh_token(refresh_token, db)

    return {"message": "Successfully logged out"}

================
File: api/v1/endpoints/counts.py
================
# from fastapi import APIRouter, Depends, HTTPException, Query
# from sqlalchemy import func
# from sqlalchemy.orm import Session
# from typing import Optional, List
# from database import get_db
# import models
# import schemas
# import logging
#
#
# router = APIRouter()
# logger = logging.getLogger(__name__)
#
#
# @router.post("/investors")
# async def get_investor_filter_counts(
#         filters: Optional[schemas.InvestorFilterParams] = None,
#         exclude_fields: List[str] = Query(default=[]),
#         db: Session = Depends(get_db)
# ):
#     """Get counts for each filter option based on current filter selections"""
#     try:
#         # Start with base query
#         base_query = db.query(models.Investor)
#
#         # Apply filters if provided
#         if filters:
#             base_query = apply_investor_filters(base_query, filters)
#
#         counts = {}
#
#         # Location counts
#         if "location" not in exclude_fields:
#             # Cities
#             city_counts = (
#                 base_query
#                 .with_entities(models.Investor.city, func.count(models.Investor.id))
#                 .filter(models.Investor.city.isnot(None))
#                 .group_by(models.Investor.city)
#                 .all()
#             )
#             counts["cities"] = {city: count for city, count in city_counts if city}
#
#             # States
#             state_counts = (
#                 base_query
#                 .with_entities(models.Investor.state, func.count(models.Investor.id))
#                 .filter(models.Investor.state.isnot(None))
#                 .group_by(models.Investor.state)
#                 .all()
#             )
#             counts["states"] = {state: count for state, count in state_counts if state}
#
#             # Countries
#             country_counts = (
#                 base_query
#                 .with_entities(models.Investor.country, func.count(models.Investor.id))
#                 .filter(models.Investor.country.isnot(None))
#                 .group_by(models.Investor.country)
#                 .all()
#             )
#             counts["countries"] = {country: count for country, count in country_counts if country}
#
#         # Industry preferences
#         if "industry" not in exclude_fields:
#             industry_counts = (
#                 base_query
#                 .with_entities(
#                     func.unnest(models.Investor.industry_preferences).label('industry'),
#                     func.count(models.Investor.id)
#                 )
#                 .filter(models.Investor.industry_preferences.isnot(None))
#                 .group_by('industry')
#                 .all()
#             )
#             counts["industries"] = {ind: count for ind, count in industry_counts if ind}
#
#         # Stage preferences
#         if "stages" not in exclude_fields:
#             stage_counts = (
#                 base_query
#                 .with_entities(
#                     func.unnest(models.Investor.stage_preferences).label('stage'),
#                     func.count(models.Investor.id)
#                 )
#                 .filter(models.Investor.stage_preferences.isnot(None))
#                 .group_by('stage')
#                 .all()
#             )
#             counts["stages"] = {stage: count for stage, count in stage_counts if stage}
#
#         # Fund types
#         if "fundType" not in exclude_fields:
#             fund_type_counts = (
#                 base_query
#                 .with_entities(models.Investor.type_of_financing, func.count(models.Investor.id))
#                 .filter(models.Investor.type_of_financing.isnot(None))
#                 .group_by(models.Investor.type_of_financing)
#                 .all()
#             )
#             counts["fundTypes"] = {ft: count for ft, count in fund_type_counts if ft}
#
#         # Gender
#         if "gender" not in exclude_fields:
#             gender_counts = (
#                 base_query
#                 .with_entities(models.Investor.gender, func.count(models.Investor.id))
#                 .filter(models.Investor.gender.isnot(None))
#                 .group_by(models.Investor.gender)
#                 .all()
#             )
#             counts["genders"] = {gender: count for gender, count in gender_counts if gender}
#
#         return counts
#
#     except Exception as e:
#         logger.error(f"Error getting investor filter counts: {str(e)}")
#         raise HTTPException(status_code=500, detail=str(e))
#
#
# @router.post("/funds")
# async def get_fund_filter_counts(
#         filters: Optional[schemas.InvestmentFundFilterParams] = None,
#         exclude_fields: List[str] = Query(default=[]),
#         db: Session = Depends(get_db)
# ):
#     """Get counts for each filter option based on current filter selections"""
#     try:
#         # Start with base query
#         base_query = db.query(models.InvestmentFund)
#
#         # Apply filters if provided
#         if filters:
#             base_query = apply_fund_filters(base_query, filters)
#
#         counts = {}
#
#         # Location counts
#         if "location" not in exclude_fields:
#             # Cities
#             city_counts = (
#                 base_query
#                 .with_entities(models.InvestmentFund.firm_city, func.count(models.InvestmentFund.id))
#                 .filter(models.InvestmentFund.firm_city.isnot(None))
#                 .group_by(models.InvestmentFund.firm_city)
#                 .all()
#             )
#             counts["cities"] = {city: count for city, count in city_counts if city}
#
#             # States
#             state_counts = (
#                 base_query
#                 .with_entities(models.InvestmentFund.firm_state, func.count(models.InvestmentFund.id))
#                 .filter(models.InvestmentFund.firm_state.isnot(None))
#                 .group_by(models.InvestmentFund.firm_state)
#                 .all()
#             )
#             counts["states"] = {state: count for state, count in state_counts if state}
#
#             # Countries
#             country_counts = (
#                 base_query
#                 .with_entities(models.InvestmentFund.firm_country, func.count(models.InvestmentFund.id))
#                 .filter(models.InvestmentFund.firm_country.isnot(None))
#                 .group_by(models.InvestmentFund.firm_country)
#                 .all()
#             )
#             counts["countries"] = {country: count for country, count in country_counts if country}
#
#         # Industry preferences
#         if "industry" not in exclude_fields:
#             industry_counts = (
#                 base_query
#                 .with_entities(
#                     func.unnest(models.InvestmentFund.industry_preferences).label('industry'),
#                     func.count(models.InvestmentFund.id)
#                 )
#                 .filter(models.InvestmentFund.industry_preferences.isnot(None))
#                 .group_by('industry')
#                 .all()
#             )
#             counts["industries"] = {ind: count for ind, count in industry_counts if ind}
#
#         # Stage preferences
#         if "stages" not in exclude_fields:
#             stage_counts = (
#                 base_query
#                 .with_entities(
#                     func.unnest(models.InvestmentFund.stage_preferences).label('stage'),
#                     func.count(models.InvestmentFund.id)
#                 )
#                 .filter(models.InvestmentFund.stage_preferences.isnot(None))
#                 .group_by('stage')
#                 .all()
#             )
#             counts["stages"] = {stage: count for stage, count in stage_counts if stage}
#
#         # Fund types
#         if "fundType" not in exclude_fields:
#             fund_type_counts = (
#                 base_query
#                 .with_entities(models.InvestmentFund.firm_type, func.count(models.InvestmentFund.id))
#                 .filter(models.InvestmentFund.firm_type.isnot(None))
#                 .group_by(models.InvestmentFund.firm_type)
#                 .all()
#             )
#             counts["fundTypes"] = {ft: count for ft, count in fund_type_counts if ft}
#
#         return counts
#
#     except Exception as e:
#         logger.error(f"Error getting fund filter counts: {str(e)}")
#         raise HTTPException(status_code=500, detail=str(e))

================
File: api/v1/endpoints/export.py
================
from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.orm import Session
from database import get_db
from models import Investor, InvestmentFund
import logging
from fastapi.responses import StreamingResponse
import io
import csv

router = APIRouter()
logger = logging.getLogger(__name__)


def generate_csv(data, headers):
    """Generate CSV file from data"""
    output = io.StringIO()
    writer = csv.DictWriter(output, fieldnames=headers)
    writer.writeheader()

    for row in data:
        clean_row = {key: (", ".join(map(str, value)) if isinstance(value, (list, tuple)) else value) for key, value in row.items()}
        writer.writerow(clean_row)

    output.seek(0)
    return output


@router.get("/lists/{list_id}/export/csv")
async def export_list_items_csv(
        list_id: int,
        db: Session = Depends(get_db)
):
    """Export items from a specific list to CSV"""
    try:
        # Get the list and verify it exists
        saved_list = db.query(models.SavedList).filter(models.SavedList.id == list_id).first()
        if not saved_list:
            raise HTTPException(status_code=404, detail="List not found")

        # Get list items
        items = crud.saved_list.get_list_items(db=db, list_id=list_id)
        if not items:
            raise HTTPException(status_code=404, detail="No items found in list")

        # Generate CSV based on list type
        if saved_list.list_type.lower() == 'investor':
            headers = [
                "id", "first_name", "last_name", "email", "phone",
                "firm_name", "city", "state", "country",
                "type_of_financing", "industry_preferences",
                "stage_preferences", "capital_managed"
            ]
        else:
            headers = [
                "id", "firm_name", "firm_type", "contact_email",
                "firm_city", "firm_state", "firm_country",
                "financing_type", "industry_preferences",
                "stage_preferences", "capital_managed"
            ]

        # Generate CSV content
        output = io.StringIO()
        writer = csv.DictWriter(output, fieldnames=headers)
        writer.writeheader()

        for item in items:
            # Clean up the row data
            row = {k: (', '.join(map(str, v)) if isinstance(v, (list, tuple)) else v)
                   for k, v in item.items() if k in headers}
            writer.writerow(row)

        output.seek(0)

        # Stream the CSV
        return StreamingResponse(
            iter([output.getvalue()]),
            media_type="text/csv",
            headers={
                'Content-Disposition': f'attachment; filename="{saved_list.name}_{datetime.now().strftime("%Y%m%d")}.csv"'
            }
        )

    except HTTPException as he:
        raise he
    except Exception as e:
        logger.error(f"Error exporting list items: {str(e)}")
        raise HTTPException(status_code=500, detail="Error generating export")

================
File: api/v1/endpoints/fund_filters.py
================
from fastapi import APIRouter
import schemas
import logging

router = APIRouter()
logger = logging.getLogger(__name__)


# Investment Fund Filter Values
@router.get('/investment-funds/email')
def return_email():
    return {
        "email": [
            {
                "label": "Has Email",
                "value": "has_email"
            },
            {
                "label": "No Email",
                "value": "no_email"
            }
        ]

    }


@router.get('/investment-funds/phone')
def return_phone():
    return {
        "phone": [
            {
                "label": "has_phone",
                "value": "has_phone"
            },
            {
                "label": "no_phone",
                "value": "no_phone"
            }
        ]

    }


@router.get('/investment-funds/address')
def return_address():
    return {
        "address": [
            {
                "label": "has_address",
                "value": "has_address"
            },
            {
                "label": "no_address",
                "value": "no_address"
            }
        ]

    }


@router.get('/investment-funds/cities')
def return_cities():
    return {
        "cities": [{
            "label": city.value, "value": city.value
        }
            for city in schemas.InvestmentFundCity
        ]
    }


@router.get('/investment-funds/states')
def return_states():
    return {
        "states": [{
            "label": state.value, "value": state.value
        }
            for state in schemas.InvestmentFundState
        ]
    }


@router.get('/investment-funds/countries')
def return_countries():
    return {
        "countries": [{
            "label": country.value, "value": country.value
        }
            for country in schemas.InvestmentFundCountry
        ]
    }


@router.get('/investment-funds/location-preferences')
def return_location_preferences():
    return {
        "location_preferences": [{
            "label": location.value, "value": location.value
        }
            for location in schemas.InvestmentFundLocationPreference
        ]
    }


@router.get('/investment-funds/industry-preferences')
def return_industry_preferences():
    return {
        "industry_preferences": [{
            "label": industry.value, "value": industry.value
        }
            for industry in schemas.InvestmentFundIndustryPreference
        ]
    }


@router.get('/investment-funds/fund-types')
def return_fund_types():
    return {
        "fund_types": [{
            "label": fund_type.value, "value": fund_type.value
        }
            for fund_type in schemas.InvestmentFundType
        ]
    }


@router.get('/investment-funds/stage-preferences')
def return_stage_preferences():
    return {
        "stage_preferences": [{
            "label": stage.value, "value": stage.value
        }
            for stage in schemas.InvestmentFundStagePreference
        ]
    }


@router.get('/investment-funds/assets-under-management')
def return_assets_under_management():
    return {
        "assets_under_management": [{
            "label": asset.value, "value": asset.value
        }
            for asset in schemas.InvestmentFundAssetsUnderManagement
        ]
    }


@router.get('/investment-funds/min-investment')
def return_min_investment():
    return {
        "minimum_investment": [{
            "label": investment.value, "value": investment.value
        }
            for investment in schemas.InvestmentFundMinInvestment
        ]
    }


@router.get('/investment-funds/max-investment')
def return_max_investment():
    return {
        "maximum_investment": [{
            "label": investment.value, "value": investment.value
        }
            for investment in schemas.InvestmentFundMaxInvestment
        ]
    }


@router.get('/investment-funds/number-of-investors')
def return_number_of_investors():
    return {
        "number_of_investors": [{
            "label": number.value, "value": number.value
        }
            for number in schemas.InvestmentFundNumberOfInvestors
        ]
    }


@router.get('/investment-funds/gender-ratio')
def return_gender_ratio():
    return {
        "gender_ratio": [{
            "label": gender.value, "value": gender.value
        }
            for gender in schemas.InvestmentFundGenderRatio
        ]
    }

================
File: api/v1/endpoints/google_auth.py
================
from fastapi import APIRouter, Depends, HTTPException, status, Request
from fastapi.responses import RedirectResponse
from sqlalchemy.orm import Session
from datetime import datetime, timedelta, UTC
import os
import requests
from google.oauth2 import id_token
from google.auth.transport import requests as google_requests
import logging
import auth
from database import get_db
import models
import schemas
from secrets import token_hex
from urllib.parse import urlencode

router = APIRouter()
logger = logging.getLogger(__name__)

GOOGLE_CLIENT_ID = os.getenv("GOOGLE_CLIENT_ID")
GOOGLE_CLIENT_SECRET = os.getenv("GOOGLE_CLIENT_SECRET")
GOOGLE_REDIRECT_URI = os.getenv("GOOGLE_REDIRECT_URI", "http://localhost:8000/api/v1/auth/google/callback")
FRONTEND_URL = os.getenv("FRONTEND_URL", "http://localhost:3000")


@router.get("/login")
async def login_via_google(request: Request):
    """Redirect to Google OAuth login with state parameter for security"""
    # Generate a random state value for CSRF protection
    state = token_hex(16)

    # Store the state in the session
    request.session["oauth_state"] = state

    # Build the Google OAuth URL
    google_auth_url = "https://accounts.google.com/o/oauth2/v2/auth"
    params = {
        "client_id": GOOGLE_CLIENT_ID,
        "redirect_uri": GOOGLE_REDIRECT_URI,
        "response_type": "code",
        "scope": "email profile",
        "access_type": "offline",
        "state": state
    }

    # Create the query string
    auth_url = f"{google_auth_url}?{urlencode(params)}"

    return RedirectResponse(auth_url)


@router.get("/callback")
async def google_auth_callback(
        request: Request,
        db: Session = Depends(get_db)
):
    """Handle Google OAuth callback"""
    try:
        # Get state parameter from callback URL
        state_param = request.query_params.get("state")
        # Get state from session
        session_state = request.session.get("oauth_state")

        # Log for debugging
        logger.info(f"Callback state param: {state_param}")
        logger.info(f"Session stored state: {session_state}")

        if not state_param or not session_state or state_param != session_state:
            logger.error("CSRF attempt detected in OAuth callback")
            logger.error(f"State param: {state_param}, Session state: {session_state}")
            return RedirectResponse(f"{FRONTEND_URL}/auth-error?message=Invalid+state+parameter")

        # Clear the state from session after verifying
        if "oauth_state" in request.session:
            del request.session["oauth_state"]

        # Get authorization code from query parameters
        code = request.query_params.get("code")
        if not code:
            logger.error("Authorization code not provided")
            return RedirectResponse(f"{FRONTEND_URL}/auth-error?message=Authorization+code+not+provided")

        # Exchange authorization code for tokens
        token_url = "https://oauth2.googleapis.com/token"
        token_data = {
            "code": code,
            "client_id": GOOGLE_CLIENT_ID,
            "client_secret": GOOGLE_CLIENT_SECRET,
            "redirect_uri": GOOGLE_REDIRECT_URI,
            "grant_type": "authorization_code"
        }

        token_response = requests.post(token_url, data=token_data)
        if token_response.status_code != 200:
            logger.error(f"Google token error: {token_response.text}")
            return RedirectResponse(f"{FRONTEND_URL}/auth-error?message=Failed+to+get+token+from+Google")

        token_info = token_response.json()

        # Verify the ID token
        try:
            id_info = id_token.verify_oauth2_token(
                token_info['id_token'],
                google_requests.Request(),
                GOOGLE_CLIENT_ID
            )
        except Exception as e:
            logger.error(f"ID token verification error: {str(e)}")
            return RedirectResponse(f"{FRONTEND_URL}/auth-error?message=Failed+to+verify+ID+token")

        # Extract user information from Google's response
        email = id_info.get('email')
        if not email:
            logger.error("Email not found in Google account")
            return RedirectResponse(f"{FRONTEND_URL}/auth-error?message=Email+not+found+in+Google+account")

        # Check if user exists in the database
        user = db.query(models.User).filter(models.User.email == email).first()

        if not user:
            # Create a new user if they don't exist
            user = models.User(
                email=email,
                first_name=id_info.get('given_name', ''),
                last_name=id_info.get('family_name', ''),
                hashed_password='',  # No password for OAuth users
                is_verified=True,  # Google already verified the email
                is_google_auth=True,
                profile_photo=id_info.get('picture')
            )
            db.add(user)
            db.commit()
            db.refresh(user)
            logger.info(f"Created new user from Google OAuth: {email}")
        elif not user.is_google_auth:
            # Update existing user to indicate they can now use Google auth
            user.is_google_auth = True

            # If user wasn't verified, verify them now (Google verified them)
            if not user.is_verified:
                user.is_verified = True

            # Update profile information if missing
            if not user.first_name:
                user.first_name = id_info.get('given_name', '')
            if not user.last_name:
                user.last_name = id_info.get('family_name', '')

            # Update profile photo if available
            if id_info.get('picture'):
                user.profile_photo = id_info.get('picture')

            db.commit()
            db.refresh(user)
            logger.info(f"Updated existing user with Google OAuth: {email}")

        # Record the login time
        user.last_login = datetime.now(UTC)
        db.commit()

        # Generate JWT token for the user
        access_token_expires = timedelta(minutes=auth.ACCESS_TOKEN_EXPIRE_MINUTES)
        access_token = auth.create_access_token(
            data={"sub": str(user.id)},
            expires_delta=access_token_expires
        )

        # Redirect to frontend with token
        redirect_url = f"{FRONTEND_URL}/auth-callback?token={access_token}"
        return RedirectResponse(redirect_url)

    except Exception as e:
        logger.error(f"Google auth error: {str(e)}")
        # Redirect to frontend with error
        error_redirect = f"{FRONTEND_URL}/auth-error?message={str(e)}"
        return RedirectResponse(error_redirect)


@router.get("/session-test")
async def session_test(request: Request):
    """Test if sessions are working properly"""
    counter = request.session.get("counter", 0)
    counter += 1
    request.session["counter"] = counter
    return {
        "count": counter,
        "session_id": request.session.get("session"),
        "all_session_data": dict(request.session)
    }

================
File: api/v1/endpoints/investment_funds.py
================
from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.orm import Session
from sqlalchemy import or_, and_
from typing import Optional, List
import models
import schemas
from database import get_db
import crud
import logging

router = APIRouter()
logger = logging.getLogger(__name__)


@router.post("/", response_model=None)
def create_fund(fund: schemas.InvestmentFundCreate, db: Session = Depends(get_db)):
    try:
        return crud.investment_fund.create(db=db, obj_in=fund)
    except Exception as  e:
        raise HTTPException(status_code=400, detail=str(e))


@router.get("/", response_model=None)
def read_funds(
        db: Session = Depends(get_db),
        page: int = Query(1, gt=0, description="Page number"),
        per_page: int = Query(50, gt=0, le=100, description="Items per page")
):
    try:
        total = db.query(models.InvestmentFund).count()
        skip = (page - 1) * per_page
        funds = crud.investment_fund.get_multi(
            db=db,
            skip=skip,
            limit=per_page
        )
        return {
            "total": total,
            "page": page,
            "per_page": per_page,
            "total_pages": -(-total // per_page),
            "results": funds
        }
    except Exception as e:
        logger.error(f"Error fetching funds: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


def apply_contact_filters(query, email=None, phone=None, address=None):
    if email:
        if email.lower() == "has_email":
            query = query.filter(models.Investor.email.isnot(None), models.Investor.email != 'NaN')
        elif email.lower() == "no_email":
            query = query.filter(or_(models.Investor.email.is_(None), models.Investor.email == 'NaN'))

    if phone:
        if phone.lower() == "has_phone":
            query = query.filter(models.Investor.phone.isnot(None), models.Investor.phone != 'NaN')
        elif phone.lower() == "no_phone":
            query = query.filter(or_(models.Investor.phone.is_(None), models.Investor.phone == 'NaN'))

    if address:
        if address.lower() == "has_address":
            query = query.filter(models.Investor.address.isnot(None), models.Investor.address != 'NaN')
        elif address.lower() == "no_address":
            query = query.filter(or_(models.Investor.address.is_(None), models.Investor.address == 'NaN'))

    return query


def string_to_float(value: str) -> tuple[float, float]:
    if not value:
        return 0, float('inf')

    ranges = {

        "$1B+": (1_000_000_000, float('inf')),


        "$100M - $500M": (100_000_000, 500_000_000),
        "$500M - $1B": (500_000_000, 1_000_000_000),
        "$25M - $100M": (25_000_000, 100_000_000),
        "$0 - $25M": (1, 25_000_000),
        "$10M - $25M": (10_000_000, 25_000_000),
        "$100M+": (100_000_000, float('inf')),
        "$1M - $10M": (1_000_000, 10_000_000),
        "$0 - $1M": (1, 1_000_000),
        "$5M - $20M": (5_000_000, 20_000_000),
        "$20M+": (20_000_000, float('inf')),
        "$1M - $5M": (1_000_000, 5_000_000),


        "$250K - $1M": (250_000, 1_000_000),
        "$0 - $250K": (0, 250_000),


        "1 - 10": (1, 9.99),
        "10 - 20": (10, 19.99),
        "20 - 30": (20, 29.99),
        "30 - 40": (30, 40)
    }

    return ranges.get(value, (0, float('inf')))


@router.get("/search")
async def search_funds_get(
        search_term: Optional[str] = None,
        page: int = Query(1, gt=0),
        per_page: int = Query(50, gt=1, le=100),
        email: Optional[str] = Query(None),
        phone: Optional[str] = Query(None),
        address: Optional[str] = Query(None),
        cities: Optional[List[str]] = Query(None),
        states: Optional[List[str]] = Query(None),
        countries: Optional[List[str]] = Query(None),
        location_preferences: Optional[list[str]] = Query(None),
        industries: Optional[List[str]] = Query(None),
        fund_types: Optional[List[str]] = Query(None),
        stages: Optional[List[str]] = Query(None),
        assets_under_management: Optional[List[str]] = Query(None),
        minimum_investment: Optional[List[str]] = Query(None),
        maximum_investment: Optional[List[str]] = Query(None),
        number_of_investors: Optional[List[str]] = Query(None),
        gender_ratio: Optional[List[str]] = Query(None),
        db: Session = Depends(get_db)
):
    """Search investment funds using query parameters"""
    try:
        query = db.query(models.InvestmentFund)

        if search_term:
            search = f"%{search_term}%"
            query = query.filter(
                models.InvestmentFund.firm_name.ilike(search) |
                models.InvestmentFund.contact_email.ilike(search) |
                models.InvestmentFund.firm_email.ilike(search)
            )

        query = apply_contact_filters(query, email, phone, address)

        if cities:
            query = query.filter(models.InvestmentFund.firm_city.in_(cities))
        if states:
            query = query.filter(models.InvestmentFund.firm_state.in_(states))
        if countries:
            query = query.filter(models.InvestmentFund.firm_country.in_(countries))
        if location_preferences:
            query = query.filter(models.InvestmentFund.geographic_preferences.overlap([location_preferences]))
        if industries:
            query = query.filter(models.InvestmentFund.industry_preferences.overlap(industries))

        if fund_types:
            query = query.filter(models.InvestmentFund.firm_type.in_(fund_types))

        if stages:
            query = query.filter(models.InvestmentFund.stage_preferences.overlap(stages))
        if assets_under_management:
            conditions = []
            for range_value in assets_under_management:
                lower, upper = string_to_float(range_value)
                conditions.append(
                    and_(
                        models.InvestmentFund.capital_managed >= lower,
                        models.InvestmentFund.capital_managed <= upper
                    )
                )
            if conditions:
                query = query.filter(or_(*conditions))

        if minimum_investment:
            conditions = []
            for range_value in minimum_investment:
                lower, upper = string_to_float(range_value)
                conditions.append(
                    and_(
                        models.InvestmentFund.min_investment >= lower,
                        models.InvestmentFund.min_investment <= upper
                    )
                )
            if conditions:
                query = query.filter(or_(*conditions))
        if maximum_investment:
            conditions = []
            for range_value in maximum_investment:
                lower, upper = string_to_float(range_value)
                conditions.append(
                    and_(
                        models.InvestmentFund.max_investment >= lower,
                        models.InvestmentFund.max_investment <= upper
                    )
                )
            if conditions:
                query = query.filter(or_(*conditions))
        if number_of_investors:
            conditions = []
            for range_value in number_of_investors:
                try:
                    lower, upper = string_to_float(range_value)
                    conditions.append(
                        and_(
                            models.InvestmentFund.number_of_investors >= lower,
                            models.InvestmentFund.number_of_investors <= upper
                        )
                    )
                except Exception as e:
                    logger.error(f"Error parsing number_of_investors range: {e}")
                    continue
            if conditions:
                query = query.filter(or_(*conditions))
        if gender_ratio:
            gender_ratios = gender_ratio if isinstance(gender_ratio, list) else [gender_ratio]
            query = query.filter(models.InvestmentFund.gender_ratio.in_(gender_ratios))

        total = query.count()
        skip = (page - 1) * per_page
        results = query.offset(skip).limit(per_page).all()

        return {
            "total": total,
            "page": page,
            "per_page": per_page,
            "total_pages": -(-total // per_page),
            "results": [crud.investment_fund.to_dict(r) for r in results]
        }

    except Exception as e:
        logger.error(f"Error searching investment funds: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/{fund_id}", response_model=None)
def read_fund(fund_id: int, db: Session = Depends(get_db)):
    try:
        db_fund = crud.investment_fund.get(db, id=fund_id)
        if db_fund is None:
            raise HTTPException(status_code=404, detail="Investment Fund not found")
        return db_fund
    except ValueError as e:
        raise HTTPException(status_code=422, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.put("/{fund_id}", response_model=None)
def update_fund(fund_id: int, fund: schemas.InvestmentFundCreate, db: Session = Depends(get_db)):
    try:
        db_fund = crud.investment_fund.update(db, id=fund_id, obj_in=fund)
        if db_fund is None:
            raise HTTPException(status_code=404, detail="Investment Fund not found")
        return db_fund
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.delete("/{fund_id}", response_model=None)
def delete_fund(fund_id: int, db: Session = Depends(get_db)):
    try:
        db_fund = crud.investment_fund.delete(db, id=fund_id)
        if db_fund is None:
            raise HTTPException(status_code=404, detail="Investment Fund not found")
        return db_fund
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

================
File: api/v1/endpoints/investor_filters.py
================
from fastapi import APIRouter
import schemas
import logging

router = APIRouter()
logger = logging.getLogger(__name__)


# Investor Filter Values
@router.get('/investors/email')
def return_email():
    return {
        "email": [
            {
                "label": "has_email",
                "value": "has_email"
            },
            {
                "label": "no_email",
                "value": "no_email"
            }
        ]

    }


@router.get('/investors/phone')
def return_phone():
    return {
        "phone": [
            {
                "label": "has_phone",
                "value": "has_phone"
            },
            {
                "label": "no_phone",
                "value": "no_phone"
            }
        ]

    }


@router.get('/investors/address')
def return_address():
    return {
        "address": [
            {
                "label": "has_address",
                "value": "has_address"
            },
            {
                "label": "no_address",
                "value": "no_address"
            }
        ]

    }


@router.get('/investors/cities')
def return_cities():
    return {
        "cities": [{
            "label": city.value, "value": city.value
        }
            for city in schemas.InvestorCity
        ]
    }


@router.get('/investors/states')
def return_states():
    return {
        "states": [{
            "label": state.value, "value": state.value
        }
            for state in schemas.InvestorState
        ]
    }


@router.get('/investors/country')
def return_country():
    return {
        "countries": [{
            "label": country.value, "value": country.value
        }
            for country in schemas.InvestorCountry
        ]
    }


@router.get('/investors/location_preferences')
def return_location_preferences():
    return {
        "location_preferences": [{
            "label": location.value, "value": location.value
        }
            for location in schemas.InvestorLocationPreference
        ]
    }


@router.get('/investors/industry_preferences')
def return_industry_preferences():
    return {
        "industry_preferences": [{
            "label": industry.value, "value": industry.value
        }
            for industry in schemas.InvestorIndustryPreference
        ]
    }


@router.get('/investors/fund_type')
def return_fund_type():
    return {
        "fund_types": [{
            "label": fund_type.value, "value": fund_type.value
        }
            for fund_type in schemas.InvestorFundType
        ]
    }


@router.get('/investors/stage_preferences')
def return_stage_preferences():
    return {
        "stage_preferences": [{
            "label": stage.value, "value": stage.value
        }
            for stage in schemas.InvestorStagePreference
        ]
    }


@router.get('/investors/assets_under_management')
def return_assets_under_management():
    return {
        "assets_under_management": [{
            "label": asset.value, "value": asset.value
        }
            for asset in schemas.InvestorAssetsUnderManagement
        ]
    }


@router.get('/investors/min_investment')
def return_min_investment():
    return {
        "minimum_investment": [{
            "label": investment.value, "value": investment.value
        }
            for investment in schemas.InvestorMinInvestment
        ]
    }


@router.get('/investors/max_investment')
def return_max_investment():
    return {
        "maximum_investment": [{
            "label": investment.value, "value": investment.value
        }
            for investment in schemas.InvestorMaxInvestment
        ]
    }


@router.get('/investors/job_title')
def return_job_title():
    return {
        "job_title": [{
            "label": title.value, "value": title.value
        }
            for title in schemas.InvestorJobTitle
        ]
    }


@router.get('/investors/number_of_investors')
def return_investors_amount():
    return {
        "number_of_investors": [{
            "label": investorsNumber.value, "value": investorsNumber.value
        }
            for investorsNumber in schemas.InvestorNumberOfInvestors
        ]
    }


@router.get('/investors/gender')
def return_gender():
    return {
        "gender": [{
            "label": gender.value, "value": gender.value
        }
            for gender in schemas.InvestorGender
        ]
    }

================
File: api/v1/endpoints/investors.py
================
from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.orm import Session
from sqlalchemy import or_, and_
from typing import Optional, List, Union
import models
import schemas
from database import get_db
import crud
import logging

router = APIRouter()
logger = logging.getLogger(__name__)


@router.post("/", response_model=None)
def create_investor(investor: schemas.InvestorCreate, db: Session = Depends(get_db)):
    try:
        return crud.investor.create(db=db, obj_in=investor)
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.get("/", response_model=None)
def read_investors(
        db: Session = Depends(get_db),
        page: int = Query(1, gt=0, description="Page number"),
        per_page: int = Query(50, gt=0, le=100, description="Number of items per page"),
):
    try:
        total = db.query(models.Investor).count()
        skip = (page - 1) * per_page
        investors = crud.investor.get_multi(
            db=db,
            skip=skip,
            limit=per_page,
        )
        return {
            "total": total,
            "page": page,
            "per_page": per_page,
            "total_pages": -(-total // per_page),
            "results": investors,
        }
    except Exception as e:
        logger.error(f"Error fetching investors: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


def normalize_enum_value(value: str) -> str:
    if not value:
        return value
    if isinstance(value, str):
        return value.title().replace('_', ' ')
    return value


def string_to_float(value: str):
    if value == "$1B+":
        return 1000000000, float('inf')
    if value == "$100M - $500M":
        return 100000000, 500000000
    if value == "$500M - $1B":
        return 500000000, 1000000000
    if value == "$25M - $100M":
        return 25000000, 100000000
    if value == "$0 - $25M":
        return 1, 25000000
    if value == "$10M - $25M":
        return 10000000, 25000000
    if value == "$100M+":
        return 100000000, float('inf')
    if value == "$1M - $10M":
        return 1000000, 10000000
    if value == "$0 - $1M":
        return 1, 1000000
    if value == "$5M - $20M":
        return 5000000, 20000000
    if value == "$20M+":
        return 20000000, float('inf')
    if value == "$1M - $5M":
        return 1000000, 5000000
    if value == "$250K - $1M":
        return 250000, 1000000
    if value == "$0 - $250K":
        return 0, 250000
    if value == "1 - 10":
        return 1, 9.99
    if value == "10 - 20":
        return 10, 19.99
    if value == "20 - 30":
        return 20, 29.99
    if value == "30 - 40":
        return 30, 40


def apply_contact_filters(query, email=None, phone=None, address=None):
    if email:
        if email.lower() == "has_email":
            query = query.filter(models.Investor.email.isnot(None), models.Investor.email != 'NaN')
        elif email.lower() == "no_email":
            query = query.filter(or_(models.Investor.email.is_(None), models.Investor.email == 'NaN'))

    if phone:
        if phone.lower() == "has_phone":
            query = query.filter(models.Investor.phone.isnot(None), models.Investor.phone != 'NaN')
        elif phone.lower() == "no_phone":
            query = query.filter(or_(models.Investor.phone.is_(None), models.Investor.phone == 'NaN'))

    if address:
        if address.lower() == "has_address":
            query = query.filter(models.Investor.address.isnot(None), models.Investor.address != 'NaN')
        elif address.lower() == "no_address":
            query = query.filter(or_(models.Investor.address.is_(None), models.Investor.address == 'NaN'))

    return query


@router.get("/search")
async def search_investors_get(
        search_term: Optional[str] = None,
        page: int = Query(1, gt=0),
        per_page: int = Query(50, gt=1, le=100),
        email: Optional[str] = Query(None),
        phone: Optional[str] = Query(None),
        address: Optional[str] = Query(None),
        cities: Optional[List[str]] = Query(None),
        states: Optional[List[str]] = Query(None),
        countries: Optional[List[str]] = Query(None),
        industries: Optional[List[str]] = Query(None),
        geographic_preferences: Optional[List[str]] = Query(None),
        fund_types: Optional[List[str]] = Query(None),
        stages: Optional[List[str]] = Query(None),
        assets_under_management: Optional[List[str]] = Query(None),
        minimum_investment: Optional[List[str]] = Query(None),
        maximum_investment: Optional[List[str]] = Query(None),
        title: Optional[List[str]] = Query(None),
        number_of_investors: Optional[List[str]] = Query(None),
        gender: Optional[str] = Query(None),
        db: Session = Depends(get_db)
):
    try:
        query = db.query(models.Investor)

        if search_term:
            search = f"%{search_term}%"
            query = query.filter(
                models.Investor.first_name.ilike(search) |
                models.Investor.last_name.ilike(search) |
                models.Investor.firm_name.ilike(search)
            )

        query = apply_contact_filters(query, email, phone, address)

        if cities:
            query = query.filter(models.Investor.city.in_(cities))
        if gender:
            query = query.filter(models.Investor.gender == gender)
        if states:
            query = query.filter(models.Investor.state.in_(states))

        if countries:
            query = query.filter(models.Investor.country.in_(countries))

        if industries:
            query = query.filter(models.Investor.industry_preferences.overlap(industries))

        if fund_types:
            query = query.filter(models.Investor.type_of_firm.in_(fund_types))

        if stages:
            query = query.filter(models.Investor.stage_preferences.overlap(stages))

        if geographic_preferences:
            query = query.filter(models.Investor.geographic_preferences.overlap(geographic_preferences))

        if assets_under_management:
            conditions = []
            for range_value in assets_under_management:
                lower, upper = string_to_float(range_value)
                conditions.append(models.Investor.capital_managed.between(lower, upper))
            if conditions:
                query = query.filter(or_(*conditions))

        if minimum_investment:
            conditions = []
            for range_value in minimum_investment:
                lower, upper = string_to_float(range_value)
                conditions.append(models.Investor.min_investment.between(lower, upper))
            if conditions:
                query = query.filter(or_(*conditions))

        if maximum_investment:
            conditions = []
            for range_value in maximum_investment:
                lower, upper = string_to_float(range_value)
                conditions.append(models.Investor.max_investment.between(lower, upper))
            if conditions:
                query = query.filter(or_(*conditions))

        if title:
            query = query.filter(models.Investor.contact_title.in_(title if isinstance(title, list) else [title]))

        if number_of_investors:
            conditions = []
            for range_value in number_of_investors:
                try:
                    lower, upper = string_to_float(range_value)
                    conditions.append(
                        and_(
                            models.Investor.number_of_investors >= lower,
                            models.Investor.number_of_investors <= upper
                        )
                    )
                except Exception as e:
                    logger.error(f"Error parsing number_of_investors range: {e}")
                    continue
            if conditions:
                query = query.filter(or_(*conditions))

        total = query.count()
        skip = (page - 1) * per_page
        results = query.offset(skip).limit(per_page).all()

        return {
            "total": total,
            "page": page,
            "per_page": per_page,
            "total_pages": -(-total // per_page),
            "results": [crud.investor.to_dict(r) for r in results]
        }

    except Exception as e:
        logger.error(f"Error searching investors: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/{investor_id}", response_model=None)
def read_investor(investor_id: int, db: Session = Depends(get_db)):
    try:
        db_investor = crud.investor.get(db, id=investor_id)
        if db_investor is None:
            raise HTTPException(status_code=404, detail="Investor not found")
        return db_investor
    except ValueError as e:
        raise HTTPException(status_code=422, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.put("/{investor_id}", response_model=None)
def update_investor(investor_id: int, investor: schemas.InvestorCreate, db: Session = Depends(get_db)):
    try:
        db_investor = crud.investor.update(db, id=investor_id, obj_in=investor)
        if db_investor is None:
            raise HTTPException(status_code=404, detail="Investor not found")
        return db_investor
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.delete("/{investor_id}", response_model=None)
def delete_investor(investor_id: int, db: Session = Depends(get_db)):
    try:
        db_investor = crud.investor.delete(db, id=investor_id)
        if db_investor is None:
            raise HTTPException(status_code=404, detail="Investor not found")
        return db_investor
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

================
File: api/v1/endpoints/lists.py
================
from fastapi import APIRouter, Depends, HTTPException
from fastapi.responses import StreamingResponse
from sqlalchemy.orm import Session, joinedload
from typing import List
import models
import schemas
from database import get_db
import crud
import logging
from datetime import datetime
import io
import csv

router = APIRouter()
logger = logging.getLogger(__name__)


@router.post("/", response_model=schemas.SavedList)
def create_list(
        list_data: schemas.SavedListCreate,
        db: Session = Depends(get_db)
):
    """Create a new saved list"""
    return crud.saved_list.create(db=db, obj_in=list_data)


@router.get("/", response_model=List[schemas.SavedList])
def get_all_lists(
        db: Session = Depends(get_db),
        skip: int = 0,
        limit: int = 100
):
    """Get all saved lists"""
    return crud.saved_list.get_multi(db=db, skip=skip, limit=limit)


@router.post("/{list_id}/investors/{investor_id}")
def add_investor_to_list(
        list_id: int,
        investor_id: int,
        db: Session = Depends(get_db)
):
    """Add an investor to a saved list"""
    success = crud.saved_list.add_investor_to_list(db=db, list_id=list_id, investor_id=investor_id)
    if not success:
        raise HTTPException(status_code=404, detail="List or investor not found")
    return {"status": "success"}


@router.post("/{list_id}/funds/{fund_id}")
def add_fund_to_list(
        list_id: int,
        fund_id: int,
        db: Session = Depends(get_db)
):
    """Add a fund to a saved list"""
    success = crud.saved_list.add_fund_to_list(db=db, list_id=list_id, fund_id=fund_id)
    if not success:
        raise HTTPException(status_code=404, detail="List or fund not found")
    return {"status": "success"}


@router.delete("/{list_id}/investors/{investor_id}")
def remove_investor_from_list(
        list_id: int,
        investor_id: int,
        db: Session = Depends(get_db)
):
    """Remove an investor from a saved list"""
    success = crud.saved_list.remove_investor_from_list(db=db, list_id=list_id, investor_id=investor_id)
    if not success:
        raise HTTPException(status_code=404, detail="List or investor not found")
    return {"status": "success"}


@router.delete("/{list_id}/funds/{fund_id}")
def remove_fund_from_list(
        list_id: int,
        fund_id: int,
        db: Session = Depends(get_db)
):
    """Remove a fund from a saved list"""
    success = crud.saved_list.remove_fund_from_list(db=db, list_id=list_id, fund_id=fund_id)
    if not success:
        raise HTTPException(status_code=404, detail="List or fund not found")
    return {"status": "success"}


@router.get("/{list_id}/items", response_model=None)
async def get_list_items_combined(
        list_id: int,
        db: Session = Depends(get_db)
):
    """Get all items in a saved list, including both investors and funds"""
    try:
        logger.info(f"Retrieving items for list {list_id}")

        # Get the list with all relationships loaded
        saved_list = db.query(models.SavedList) \
            .options(joinedload(models.SavedList.saved_investors)) \
            .options(joinedload(models.SavedList.saved_funds)) \
            .filter(models.SavedList.id == list_id) \
            .first()

        if not saved_list:
            logger.error(f"List with id {list_id} not found")
            raise HTTPException(status_code=404, detail="List not found")

        # Get investors if any exist
        investors = []
        if saved_list.saved_investors:
            investor_ids = [inv.id for inv in saved_list.saved_investors]
            db_investors = db.query(models.Investor) \
                .filter(models.Investor.id.in_(investor_ids)) \
                .all()
            investors = [crud.investor.to_dict(inv) for inv in db_investors]
            logger.info(f"Found {len(investors)} investors")

        # Get funds if any exist
        funds = []
        if saved_list.saved_funds:
            fund_ids = [fund.id for fund in saved_list.saved_funds]
            db_funds = db.query(models.InvestmentFund) \
                .filter(models.InvestmentFund.id.in_(fund_ids)) \
                .all()
            funds = [crud.investment_fund.to_dict(fund) for fund in db_funds]
            logger.info(f"Found {len(funds)} funds")

        # Combine both types of items into a single response
        response = {
            "list_id": list_id,
            "list_name": saved_list.name,
            "list_type": saved_list.list_type,
            "total_items": len(investors) + len(funds),
            "items": {
                "investors": {
                    "count": len(investors),
                    "data": investors
                },
                "funds": {
                    "count": len(funds),
                    "data": funds
                }
            }
        }

        logger.info(f"Successfully retrieved {response['total_items']} items from list")
        return response

    except Exception as e:
        logger.error(f"Error retrieving list items: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/{list_id}/items/by-type", response_model=None)
async def get_list_items_by_type(
        list_id: int,
        db: Session = Depends(get_db)
):
    """Get all items in a saved list based on list type"""
    try:
        logger.info(f"Attempting to retrieve items for list {list_id}")

        # Get the list with relationships loaded
        saved_list = db.query(models.SavedList) \
            .options(joinedload(models.SavedList.saved_investors)) \
            .options(joinedload(models.SavedList.saved_funds)) \
            .filter(models.SavedList.id == list_id) \
            .first()

        if not saved_list:
            logger.error(f"List with id {list_id} not found")
            raise HTTPException(status_code=404, detail="List not found")

        logger.info(f"Found list: {saved_list.name} (type: {saved_list.list_type})")

        # Convert items to dictionaries based on list type
        if saved_list.list_type.lower() == 'investor':
            # Get the actual investor records
            investor_ids = [inv.id for inv in saved_list.saved_investors]
            investors = db.query(models.Investor) \
                .filter(models.Investor.id.in_(investor_ids)) \
                .all()

            items = [crud.investor.to_dict(inv) for inv in investors]
            logger.info(f"Retrieved {len(items)} investors")
        else:
            # Get the actual fund records
            fund_ids = [fund.id for fund in saved_list.saved_funds]
            funds = db.query(models.InvestmentFund) \
                .filter(models.InvestmentFund.id.in_(fund_ids)) \
                .all()

            items = [crud.investment_fund.to_dict(fund) for fund in funds]
            logger.info(f"Retrieved {len(items)} funds")

        # Return formatted response
        return {
            "list_id": list_id,
            "list_name": saved_list.name,
            "list_type": saved_list.list_type,
            "total_items": len(items),
            "items": items
        }

    except Exception as e:
        logger.error(f"Error retrieving list items: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"Internal server error: {str(e)}"
        )


@router.put("/{list_id}/type", response_model=None)
async def update_list_type(
        list_id: int,
        list_type: str,
        db: Session = Depends(get_db)
):
    """Update the type of a saved list"""
    try:
        saved_list = db.query(models.SavedList).filter(models.SavedList.id == list_id).first()
        if not saved_list:
            raise HTTPException(status_code=404, detail="List not found")

        # Update list type
        saved_list.list_type = list_type
        db.commit()

        return {
            "message": "List type updated successfully",
            "list_id": list_id,
            "new_type": list_type
        }
    except Exception as e:
        logger.error(f"Error updating list type: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/export/{list_id}")
async def export_list(
        list_id: int,
        db: Session = Depends(get_db)
):
    """Export all items from a specific list"""
    try:
        # Get the list and its items
        items_response = await get_list_items_combined(list_id, db)

        # Process investors
        investor_data = items_response["items"]["investors"]["data"]
        investor_fields = [
            "id", "first_name", "last_name", "email", "phone",
            "firm_name", "city", "state", "country",
            "type_of_financing", "industry_preferences",
            "stage_preferences", "capital_managed"
        ]

        # Process funds
        fund_data = items_response["items"]["funds"]["data"]
        fund_fields = [
            "id", "firm_name", "firm_type", "contact_email",
            "firm_city", "firm_state", "firm_country",
            "financing_type", "industry_preferences",
            "stage_preferences", "capital_managed"
        ]

        # Generate CSV
        output = io.StringIO()

        # Write investors section
        writer = csv.DictWriter(output, fieldnames=investor_fields)
        writer.writeheader()
        for investor in investor_data:
            row = {k: (', '.join(map(str, v)) if isinstance(v, (list, tuple)) else v)
                   for k, v in investor.items() if k in investor_fields}
            writer.writerow(row)

        # Add separator
        output.write("\n--- Investment Funds ---\n\n")

        # Write funds section
        writer = csv.DictWriter(output, fieldnames=fund_fields)
        writer.writeheader()
        for fund in fund_data:
            row = {k: (', '.join(map(str, v)) if isinstance(v, (list, tuple)) else v)
                   for k, v in fund.items() if k in fund_fields}
            writer.writerow(row)

        output.seek(0)

        return StreamingResponse(
            iter([output.getvalue()]),
            media_type="text/csv",
            headers={
                "Content-Disposition": f"attachment; filename=list_{list_id}_export_{datetime.now().strftime('%Y%m%d')}.csv"
            }
        )

    except Exception as e:
        logger.error(f"Error exporting list: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

================
File: api/v1/endpoints/utils.py
================
from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.orm import Session
from typing import Dict
import models
from database import get_db
import logging

router = APIRouter()
logger = logging.getLogger(__name__)


@router.get("/stats")
def get_database_stats(db: Session = Depends(get_db)) -> Dict:
    """Get database statistics"""
    try:
        total_investors = db.query(models.Investor).count()
        total_funds = db.query(models.InvestmentFund).count()
        return {
            "total_investors": total_investors,
            "total_investment_funds": total_funds
        }
    except Exception as e:
        logger.error(f"Error getting stats: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/test-pagination")
def test_pagination(
        db: Session = Depends(get_db),
        page: int = Query(1, gt=0),
        per_page: int = Query(100, gt=0, le=500)
):
    """Test Pagination with metrics"""
    try:
        skip = (page - 1) * per_page

        # Get Investors
        total_investors = db.query(models.Investor).count()
        investors = db.query(models.Investor).offset(skip).limit(per_page).all()

        # Get Investment Funds
        total_funds = db.query(models.InvestmentFund).count()
        funds = db.query(models.InvestmentFund).offset(skip).limit(per_page).all()

        return {
            "pagination": {
                "page": page,
                "per_page": per_page,
                "total_investors": total_investors,
                "total_funds": total_funds,
                "total_pages_investors": -(-total_investors // per_page),
                "total_pages_funds": -(-total_funds // per_page),
            },
            "current_page_data": {
                "investor_count": len(investors),
                "funds_count": len(funds),
                "skip": skip,
                "investors_sample": [{"id": inv.id, "email": inv.email} for inv in investors[:5]],
                "funds_sample": [{"id": fund.id, "name": fund.firm_name} for fund in funds[:5]]
            }
        }
    except Exception as e:
        logger.error(f"Error in test-pagination: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

================
File: api/v1/dependencies.py
================
from typing import Optional, Tuple


def parse_investment_range(range_str: str) -> Tuple[Optional[float], Optional[float]]:
    """Convert string investment range to numeric min/max values"""
    if not range_str:
        return None, None

    ranges = {
        # Assets Under Management
        "1B_PLUS": (1_000_000_000, None),
        "100M_500M": (100_000_000, 500_000_000),
        "500M_1B": (500_000_000, 1_000_000_000),
        "25M_100M": (25_000_000, 100_000_000),
        "0_25M": (0, 25_000_000),

        # Min Investment
        "25K_250K": (25_000, 250_000),
        "250K_1M": (250_000, 1_000_000),
        "1M_5M": (1_000_000, 5_000_000),
        "5M_PLUS": (5_000_000, None),

        # Max Investment
        "25M_150M": (25_000_000, 150_000_000),
        "10M_25M": (10_000_000, 25_000_000),
        "1M_10M": (1_000_000, 10_000_000),
        "150M_PLUS": (150_000_000, None)
    }

    return ranges.get(range_str, (None, None))

================
File: middleware/auth_rate_limit.py
================
from fastapi import HTTPException, Request
from datetime import datetime, timedelta, UTC
import logging
from typing import Dict, List
from fastapi import FastAPI
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.responses import JSONResponse
import time

logger = logging.getLogger(__name__)


class AuthRateLimitMiddleware(BaseHTTPMiddleware):
    def __init__(
            self,
            app: FastAPI,
            login_limit: int = 5,  # Maximum login attempts per window
            window_seconds: int = 300,  # 5-minute window
            block_seconds: int = 900  # 15-minute block after exceeding limit
    ):
        super().__init__(app)
        self.login_attempts: Dict[str, List[datetime]] = {}
        self.blocked_ips: Dict[str, datetime] = {}
        self.login_limit = login_limit
        self.window_seconds = window_seconds
        self.block_seconds = block_seconds

    async def dispatch(self, request: Request, call_next):
        # Only apply to auth endpoints
        path = request.url.path
        if not path.startswith("/api/v1/auth") or request.method != "POST":
            return await call_next(request)

        # Get client IP
        client_ip = request.client.host if request.client else "unknown"

        # Check if IP is blocked
        if client_ip in self.blocked_ips:
            block_until = self.blocked_ips[client_ip]
            if datetime.now(UTC) < block_until:
                remaining_seconds = int((block_until - datetime.now(UTC)).total_seconds())
                return JSONResponse(
                    status_code=429,
                    content={
                        "detail": f"Too many failed attempts. Try again in {remaining_seconds} seconds."
                    }
                )
            else:
                # Remove from blocked list if time has expired
                del self.blocked_ips[client_ip]

        # Cleanup old attempts
        now = datetime.now(UTC)
        cutoff = now - timedelta(seconds=self.window_seconds)

        if client_ip in self.login_attempts:
            self.login_attempts[client_ip] = [
                t for t in self.login_attempts[client_ip] if t > cutoff
            ]

            # Check if limit reached
            if len(self.login_attempts[client_ip]) >= self.login_limit:
                # Block IP
                self.blocked_ips[client_ip] = now + timedelta(seconds=self.block_seconds)
                logger.warning(f"IP {client_ip} blocked for {self.block_seconds} seconds due to too many auth attempts")
                return JSONResponse(
                    status_code=429,
                    content={
                        "detail": f"Too many authentication attempts. Try again in {self.block_seconds} seconds."
                    }
                )

        # Process the request
        response = await call_next(request)

        # If auth failed, record the attempt
        if path in ["/api/v1/auth/login", "/api/v1/auth/refresh"] and response.status_code == 401:
            if client_ip not in self.login_attempts:
                self.login_attempts[client_ip] = []

            self.login_attempts[client_ip].append(now)
            logger.info(
                f"Failed auth attempt from {client_ip} ({len(self.login_attempts[client_ip])}/{self.login_limit})")

        return response

================
File: middleware/rate_limit.py
================
from fastapi import HTTPException, Request
from datetime import datetime, timedelta, UTC
import logging
from typing import Dict, Optional
from fastapi import FastAPI
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.responses import JSONResponse

logger = logging.getLogger(__name__)


class RateLimitMiddleware(BaseHTTPMiddleware):
    def __init__(
            self,
            app: FastAPI,
            rate_limit_duration: int = 24 * 60 * 60,  # 24 hours in seconds
            default_limit: int = 1000  # Default requests per duration
    ):
        super().__init__(app)
        self.requests: Dict[str, list] = {}
        self.rate_limit_duration = rate_limit_duration
        self.default_limit = default_limit

        # Define tier limits - you can modify these based on your needs
        self.tier_limits = {
            "basic": 1000,  # 1000 requests per day
            "professional": 5000,  # 5000 requests per day
            "enterprise": 10000  # 10000 requests per day
        }

    async def dispatch(self, request: Request, call_next):
        # Get client identifier (you might want to use API key or token instead)
        client_id = self._get_client_identifier(request)

        # Get user's tier (you'll need to implement this based on your auth system)
        user_tier = await self._get_user_tier(request)

        try:
            # Check rate limit
            await self._check_rate_limit(client_id, user_tier)

            # Process the request
            response = await call_next(request)
            return response

        except HTTPException as exc:
            return JSONResponse(
                status_code=exc.status_code,
                content={"detail": exc.detail}
            )

    def _get_client_identifier(self, request: Request) -> str:
        # You might want to use API key or token instead of IP
        return request.client.host if request.client else "unknown"

    async def _get_user_tier(self, request: Request) -> str:
        # Implement your logic to get user tier from auth token/header
        # This is a placeholder - modify based on your auth system
        return "basic"

    async def _check_rate_limit(self, client_id: str, tier: str):
        now = datetime.now(UTC)

        # Initialize client's request history if not exists
        if client_id not in self.requests:
            self.requests[client_id] = []

        # Remove old requests
        cutoff_time = now - timedelta(seconds=self.rate_limit_duration)
        self.requests[client_id] = [
            req_time for req_time in self.requests[client_id]
            if req_time > cutoff_time
        ]

        # Get limit based on tier
        limit = self.tier_limits.get(tier, self.default_limit)

        # Check if limit exceeded
        if len(self.requests[client_id]) >= limit:
            logger.warning(f"Rate limit exceeded for client {client_id} (tier: {tier})")
            raise HTTPException(
                status_code=429,
                detail=f"Rate limit of {limit} requests per {self.rate_limit_duration // 3600} hours exceeded"
            )

        # Add current request
        self.requests[client_id].append(now)


# Usage example for clearing old rate limit data
def cleanup_rate_limits(rate_limiter: RateLimitMiddleware):
    """Cleanup old rate limit data periodically"""
    now = datetime.now(UTC)
    cutoff_time = now - timedelta(seconds=rate_limiter.rate_limit_duration)

    for client_id in list(rate_limiter.requests.keys()):
        rate_limiter.requests[client_id] = [
            req_time for req_time in rate_limiter.requests[client_id]
            if req_time > cutoff_time
        ]
        # Remove empty client records
        if not rate_limiter.requests[client_id]:
            del rate_limiter.requests[client_id]

================
File: scripts/cleanup_token.py
================
#!/usr/bin/env python
"""
Script to clean up expired refresh tokens.
Can be run as a cron job to keep the database tidy.
"""
import logging
import os
import sys
from datetime import datetime, UTC

# Add the project root to the Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database import get_db
from auth import cleanup_expired_tokens

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('token_cleanup.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


def main():
    """Main function to cleanup expired tokens"""
    try:
        logger.info("Starting expired token cleanup")
        db = next(get_db())

        deleted_count = cleanup_expired_tokens(db)

        logger.info(f"Cleanup complete. Removed {deleted_count} expired tokens")
    except Exception as e:
        logger.error(f"Error cleaning up tokens: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main()

================
File: scripts/import_data.py
================
import logging
import os
import sys
import traceback
from typing import Type, Union

import pandas as pd
import sqlalchemy
from sqlalchemy.dialects.postgresql import insert
from sqlalchemy.orm import Session

from database import engine
from models import Base, Investor, InvestmentFund

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

Base.metadata.create_all(bind=engine)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('import.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


def get_column_mappings(model):
    common_mappings = {
        'Industry Preferences': 'industry_preferences',
        'Geographic Preferences': 'geographic_preferences',
        'Stage Preferences': 'stage_preferences',
        'Capital Managed': 'capital_managed',
        'Number Of Investors': 'number_of_investors',
    }

    if model == InvestmentFund:
        return {
            **common_mappings,
            'Full Name': 'full_name',
            'Title': 'title',
            'Contact Email': 'contact_email',
            'Contact Phone': 'contact_phone',
            'Firm Name': 'firm_name',
            'Firm Email': 'firm_email',
            'Firm Phone': 'firm_phone',
            'Firm Website': 'firm_website',
            'Firm Address': 'firm_address',
            'Firm City': 'firm_city',
            'Firm State': 'firm_state',
            'Firm Zip': 'firm_zip',
            'Firm Country': 'firm_country',
            'Office Type': 'office_type',
            'Financing Type': 'financing_type',
            'Min. Investment': 'min_investment',
            'Max. Investment': 'max_investment',
            'Firm Type': 'firm_type',
            'Gender Ratio': 'gender_ratio'
        }
    else:  # Investor
        return {
            **common_mappings,
            'Prefix': 'prefix',
            'First Name': 'first_name',
            'Last Name': 'last_name',
            'Gender': 'gender',
            'Contact Title': 'contact_title',
            'Email': 'email',
            'Phone': 'phone',
            'Address': 'address',
            'Office Website': 'office_website',
            'Firm Name': 'firm_name',
            'City': 'city',
            'State': 'state',
            'Country': 'country',
            'Type Of Firm': 'type_of_firm',
            'Type of Financing': 'type_of_financing',
            'Min Investment': 'min_investment',
            'Max Investment': 'max_investment'
        }


def convert_currency(value):
    if pd.isna(value) or value is None or value == '':
        return None
    try:
        if isinstance(value, (int, float)):
            return float(value) if value > 0 else None
        if isinstance(value, str):
            value = value.replace('$', '').replace(',', '').replace(' ', '')
            if '-' in value:
                parts = value.split('-')
                values = [float(p) for p in parts if p.strip()]
                return sum(values) / len(values) if values else None
            return float(value) if float(value) > 0 else None
        return None
    except Exception as e:
        logger.error(f"Error converting currency value '{value}': {str(e)}")
        return None


def clean_list_field(value):
    if pd.isna(value) or value in ('', '[""]'):
        return None
    try:
        if isinstance(value, str):
            value = value.strip('[]').replace('"', '').replace("'", '')
            items = [item.strip() for item in value.split(',')]
            items = list(set(item for item in items if item))
            return items if items else None
        elif isinstance(value, list):
            items = [str(item).strip() for item in value if item]
            return list(set(items)) if items else None
        return None
    except Exception as e:
        logger.error(f"List cleaning error for {value}: {str(e)}")
        return None


def clean_and_convert_data(df: pd.DataFrame, model: Type[Union[Investor, InvestmentFund]]) -> pd.DataFrame:
    df = df.replace({
        'Unknown': None, '': None, 'N/A': None, 'nan': None,
        'NULL': None, 'None': None, '["]': None, '[]': None
    })

    numeric_cols = ['min_investment', 'max_investment', 'capital_managed']
    for col in numeric_cols:
        if col in df.columns:
            df[col] = df[col].apply(convert_currency)

    if 'number_of_investors' in df.columns:
        df['number_of_investors'] = df['number_of_investors'].apply(lambda x: float(x) if pd.notnull(x) else None)

    if 'gender_ratio' in df.columns:
        df['gender_ratio'] = df['gender_ratio'].astype(str)

    list_fields = ['industry_preferences', 'geographic_preferences', 'stage_preferences']
    if model == Investor:
        list_fields.append('type_of_financing')
    elif model == InvestmentFund:
        list_fields.append('financing_type')

    for field in list_fields:
        if field in df.columns:
            df[field] = df[field].apply(clean_list_field)

    return df


def import_data(csv_file: str, model: Type[Union[Investor, InvestmentFund]], session: Session):
    logger.info(f"\nProcessing {model.__name__} data from {csv_file}")

    try:
        df = pd.read_csv(csv_file)
        logger.info(f"Successfully read CSV with {len(df)} rows")

        df = df.rename(columns=get_column_mappings(model))
        df_cleaned = clean_and_convert_data(df, model)
        logger.info("Data cleaning completed")

    except Exception as e:
        logger.error(f"Error processing CSV file {csv_file}: {str(e)}")
        raise

    chunk_size = 1000
    records_processed = 0
    errors = 0

    for start_idx in range(0, len(df_cleaned), chunk_size):
        chunk = df_cleaned.iloc[start_idx:start_idx + chunk_size]

        for _, row in chunk.iterrows():
            try:
                record = {k: v for k, v in row.items()
                          if v is not None and k in model.__table__.columns.keys()}

                stmt = insert(model).values(**record)
                session.execute(stmt)
                session.commit()
                records_processed += 1

            except Exception as e:
                errors += 1
                logger.error(f"Error inserting record: {str(e)}")
                logger.error(f"Problematic record: {record}")
                session.rollback()

            if records_processed % 100 == 0:
                logger.info(f"Processed {records_processed} records. Errors: {errors}")

    logger.info(f"\nImport completed for {model.__name__}:")
    logger.info(f"Total records processed: {records_processed}")
    logger.info(f"Total errors: {errors}")

    return records_processed


def verify_import(session: Session, model: Type[Union[Investor, InvestmentFund]]):
    logger.info(f"\nVerifying {model.__name__} import:")
    total = session.query(model).count()
    logger.info(f"Total records: {total}")

    for col in ['min_investment', 'max_investment', 'capital_managed']:
        count = session.query(model).filter(getattr(model, col).isnot(None)).count()
        logger.info(f"Non-null {col}: {count}")

        samples = session.query(model).filter(
            getattr(model, col).isnot(None)
        ).limit(5).all()
        if samples:
            logger.info(f"Sample {col} values:")
            for sample in samples:
                logger.info(f"  {getattr(sample, col)}")


def main():
    try:
        logger.info(f"BASE_DIR: {BASE_DIR}")

        with Session(engine) as session:
            try:
                investors_csv = f"{BASE_DIR}/data/investors_cleaned.csv"
                if os.path.exists(investors_csv):
                    logger.info("Found investors CSV file")
                    total_investors = import_data(investors_csv, Investor, session)
                    print(total_investors)
                    verify_import(session, Investor)
                else:
                    logger.error(f"Investors CSV not found at {investors_csv}")

                funds_csv = f"{BASE_DIR}/data/vc_funds.csv"
                if os.path.exists(funds_csv):
                    logger.info("Found funds CSV file")
                    total_funds = import_data(funds_csv, InvestmentFund, session)
                    print(total_funds)
                    verify_import(session, InvestmentFund)
                else:
                    logger.error(f"Funds CSV not found at {funds_csv}")

            except Exception as e:
                logger.error(f"Database session error: {str(e)}")
                raise

    except Exception as e:
        logger.error(f"An error occurred: {str(e)}")
        logger.error("Full traceback:")
        logger.error(traceback.format_exc())
        logger.error(f"Exception type: {type(e).__name__}")
        logger.error(f"Exception args: {e.args}")
        logger.error(f"Python version: {sys.version}")
        logger.error(f"Platform: {sys.platform}")
        logger.error(f"Working directory: {os.getcwd()}")
        logger.error(f"pandas version: {pd.__version__}")
        logger.error(f"sqlalchemy version: {sqlalchemy.__version__}")
        raise


if __name__ == "__main__":
    main()

================
File: scripts/reset_database.py
================
from sqlalchemy import create_engine, inspect
from database import SQLALCHEMY_DATABASE_URL
from models import Base


def reset_database():
    engine = create_engine(SQLALCHEMY_DATABASE_URL)
    inspector = inspect(engine)

    # Get list of all table names
    table_names = inspector.get_table_names()

    # Drop all tables
    Base.metadata.drop_all(bind=engine)
    print(f"Dropped tables: {', '.join(table_names)}")

    # Recreate all tables
    Base.metadata.create_all(bind=engine)
    print("Recreated all tables.")


if __name__ == "__main__":
    reset_database()

================
File: scripts/update_schema.py
================
from sqlalchemy import create_engine
from database import SQLALCHEMY_DATABASE_URL
from models import Base


def update_schema():
    engine = create_engine(SQLALCHEMY_DATABASE_URL)

    # This will create tables that don't exist, but won't modify existing tables
    Base.metadata.create_all(bind=engine)

    print("Database schema updated.")


if __name__ == "__main__":
    update_schema()

================
File: scripts/user_table.py
================
from database import engine, Base
import models
import logging

logger = logging.getLogger(__name__)


def add_user_table():
    try:
        logger.info("Creating User table if it doesn't exist...")
        models.User.__table__.create(bind=engine, checkfirst=True)
        logger.info("User table created successfully")
    except Exception as e:
        logger.error(f"Error creating User table: {str(e)}")
        raise


if __name__ == "__main__":
    add_user_table()

================
File: .gitignore
================
# Ignore Python cache files
__pycache__/
*.pyc

# Ignore environment variables
.env

# Ignore virtual environments
.venv/
venv/

# Ignore logs and temporary files
*.log

# Ignore IDE-specific files
.idea/

# Ignore system-specific files
.DS_Store
Thumbs.db

package-lock.json
repomix.config.json
.repomixignore

================
File: app.py
================
from fastapi import FastAPI, Depends
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
from api.v1.endpoints import (
    investors,
    investment_funds,
    export,
    utils,
    lists,
    investor_filters,
    fund_filters,
    auth,
    google_auth
)
from database import engine, get_db, test_db_connection
import models
import os
import logging
import sys
from middleware.rate_limit import RateLimitMiddleware
from starlette.middleware.sessions import SessionMiddleware
from middleware.auth_rate_limit import AuthRateLimitMiddleware
from starlette.middleware.httpsredirect import HTTPSRedirectMiddleware


# Configure logging
def setup_logging():
    """Configure logging to output to console only"""

    # Configure logging format
    log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    formatter = logging.Formatter(log_format)

    # Set up console handler
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)

    # Configure root logger
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)

    # Remove any existing handlers
    root_logger.handlers = []
    root_logger.addHandler(console_handler)

    return root_logger


logger = setup_logging()


# Startup and shutdown events
@asynccontextmanager
async def lifespan(_: FastAPI):
    # Startup
    logger.info("Starting application...")
    if not test_db_connection():
        logger.error("Database connection failed!")
        sys.exit(1)

    models.Base.metadata.create_all(bind=engine)
    logger.info("Database tables verified")

    yield

    # Shutdown
    logger.info("Shutting down application...")


# Create FastAPI app
app = FastAPI(
    title="Investor Database API",
    description="API for managing investors and investment funds database",
    version="1.0.0",
    lifespan=lifespan
)
if os.getenv("ENVIRONMENT") == "production":
    app.add_middleware(HTTPSRedirectMiddleware)

app.add_middleware(AuthRateLimitMiddleware)

app.add_middleware(
    SessionMiddleware,
    secret_key=os.getenv("SECRET_KEY", "4GGdb2Ol15zbAeGzQQdwxH9WdW8HPCjV"),
    max_age=3600,
    same_site="lax"
)

app.add_middleware(
    RateLimitMiddleware,
    rate_limit_duration=24 * 60 * 60,  # 24 hours in seconds
    default_limit=1000  # Default requests per day
)

# Configure CORS
origins = ["*"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/health")
async def health_check():
    """API health check endpoint"""
    return {
        "status": "healthy",
        "version": "1.0.0",
        "environment": os.getenv("ENVIRONMENT", "development"),
        "database": "connected" if test_db_connection() else "error"
    }


# Public routes - no auth required
public_routes = [
    (utils.router, "/api/v1", "utils")
]

for router, prefix, tag in public_routes:
    app.include_router(router, prefix=prefix, tags=[tag])

protected_routes = [
    (investors.router, "/api/v1/investors", "investors", "basic"),
    (investment_funds.router, "/api/v1/funds", "funds", "basic"),
    (export.router, "/api/v1/export", "export", "professional"),
    (lists.router, "/api/v1/lists", "lists", "basic"),
    (investor_filters.router, "/api/v1/filters", "Investor Filters", "basic"),
    (fund_filters.router, "/api/v1/filters", "Fund Filters", "basic"),
    (auth.router, "/api/v1/auth", "authentication", "basic"),
    (google_auth.router, "/api/v1/auth/google", "google authentication", "basic")
]

for router, prefix, tag, _ in protected_routes:
    app.include_router(
        router,
        prefix=prefix,
        tags=[tag]
    )

if __name__ == "__main__":
    import uvicorn

    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=8000,
        reload=True if os.getenv("ENVIRONMENT") == "development" else False
    )

================
File: auth.py
================
import os
import secrets
import string
from datetime import datetime, timedelta, UTC
from typing import Optional, Dict

from dotenv import load_dotenv
from fastapi import Depends, HTTPException, status
from fastapi.security import OAuth2PasswordBearer
from jose import JWTError, jwt
from passlib.context import CryptContext
from sqlalchemy.orm import Session

import models
from database import get_db
import bcrypt
import logging

load_dotenv()

logger = logging.getLogger(__name__)

SECRET_KEY = os.getenv("JWT_SECRET_KEY")
if not SECRET_KEY:
    raise ValueError("JWT_SECRET_KEY must be set in environment variables")
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 60 * 24

pwd_context = CryptContext(
    schemes=["bcrypt"],
    deprecated="auto",
    bcrypt__ident="2b",
    bcrypt__default_rounds=12
)

oauth2_scheme = OAuth2PasswordBearer(tokenUrl="api/v1/auth/login")


def verify_password(plain_password, hashed_password):
    try:
        if not hashed_password or hashed_password.strip() == '':
            return False

        # Convert inputs to bytes if they're strings
        if isinstance(plain_password, str):
            plain_password = plain_password.encode('utf-8')
        if isinstance(hashed_password, str):
            hashed_password = hashed_password.encode('utf-8')

        # Use bcrypt directly to verify
        return bcrypt.checkpw(plain_password, hashed_password)
    except Exception as e:
        # Log the error
        logger.error(f"Password verification error: {str(e)}")
        # Return False for any error - this indicates password verification failed
        return False


def set_password_for_oauth_user(db: Session, user_id: int, password: str) -> bool:
    try:
        user = db.query(models.User).filter(models.User.id == user_id).first()
        if not user:
            return False

        # Set the password hash
        user.hashed_password = get_password_hash(password)
        db.commit()
        return True
    except Exception as e:
        logger.error(f"Error setting password for OAuth user: {str(e)}")
        db.rollback()
        return False


def get_password_hash(password):
    return pwd_context.hash(password)


def create_access_token(data: Dict, expires_delta: Optional[timedelta] = None):
    to_encode = data.copy()

    if expires_delta:
        expire = datetime.now(UTC) + expires_delta
    else:
        expire = datetime.now(UTC) + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)

    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt


def generate_token(length=32):
    alphabet = string.ascii_letters + string.digits
    return ''.join(secrets.choice(alphabet) for _ in range(length))


async def get_current_user(token: str = Depends(oauth2_scheme), db: Session = Depends(get_db)):
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )

    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        user_id: str = payload.get("sub")
        if user_id is None:
            raise credentials_exception
    except JWTError:
        raise credentials_exception

    user = db.query(models.User).filter(models.User.id == user_id).first()
    if user is None:
        raise credentials_exception

    return user


def create_refresh_token(user_id: int, db: Session) -> str:
    expires_delta = timedelta(days=int(os.getenv("REFRESH_TOKEN_EXPIRE_DAYS", "7")))
    expires_at = datetime.now(UTC) + expires_delta

    # Generate token
    token = secrets.token_urlsafe(64)

    # Create refresh token record
    refresh_token = models.RefreshToken(
        token=token,
        user_id=user_id,
        expires_at=expires_at
    )

    db.add(refresh_token)
    db.commit()

    return token


def verify_refresh_token(token: str, db: Session) -> Optional[models.User]:
    # Get token from database
    db_token = db.query(models.RefreshToken).filter(
        models.RefreshToken.token == token,
        models.RefreshToken.revoked == False,
        models.RefreshToken.expires_at > datetime.now(UTC)
    ).first()

    if not db_token:
        return None

    return db_token.user


def revoke_refresh_token(token: str, db: Session) -> bool:
    """Revoke a refresh token (for logout)"""
    db_token = db.query(models.RefreshToken).filter(
        models.RefreshToken.token == token,
        models.RefreshToken.revoked == False
    ).first()

    if not db_token:
        return False

    db_token.revoked = True
    db.commit()
    return True


def cleanup_expired_tokens(db: Session) -> int:
    """Remove expired tokens from the database
    Returns the number of tokens deleted"""
    now = datetime.now(UTC)
    result = db.query(models.RefreshToken).filter(
        models.RefreshToken.expires_at < now
    ).delete()
    db.commit()
    return result

================
File: crud.py
================
from sqlalchemy.orm import Session
from sqlalchemy import or_, String, Text
import models
import schemas
from typing import TypeVar, Generic, List, Any, Dict, Optional, Type
import logging
import math
from decimal import Decimal

ModelType = TypeVar("ModelType", bound=models.Base)
CreateSchemaType = TypeVar("CreateSchemaType", bound=schemas.BaseModel)

logger = logging.getLogger(__name__)


class CRUDBase(Generic[ModelType, CreateSchemaType]):
    def __init__(self, model: Type[ModelType]):
        self.model = model

    def get_multi(
            self,
            db: Session,
            skip: int = 0,
            limit: int = 100,
            search: Optional[str] = None,
            filters: Optional[Dict] = None,
            sort_by: Optional[str] = None,
            sort_desc: bool = False
    ) -> List[Dict]:
        try:
            query = db.query(self.model)

            # Apply text search across string fields
            if search:
                search_filters = []
                for column in self.model.__table__.columns:
                    if isinstance(column.type, (String, Text)):
                        search_filters.append(getattr(self.model, column.key).ilike(f"%{search}%"))
                if search_filters:
                    query = query.filter(or_(*search_filters))

            # Apply filters
            if filters:
                for key, value in filters.items():
                    if hasattr(self.model, key):
                        if isinstance(value, dict):
                            col = getattr(self.model, key)
                            for op, val in value.items():
                                if op == "gte":
                                    query = query.filter(col >= val)
                                elif op == "lte":
                                    query = query.filter(col <= val)
                        elif isinstance(value, (list, tuple)):
                            # Handle array overlaps for preferences
                            col = getattr(self.model, key)
                            if hasattr(col, 'overlap'):
                                query = query.filter(col.overlap(value))
                            else:
                                query = query.filter(col.in_(value))
                        else:
                            query = query.filter(getattr(self.model, key) == value)

            # Apply sorting
            if sort_by and hasattr(self.model, sort_by):
                order_col = getattr(self.model, sort_by)
                if sort_desc:
                    order_col = order_col.desc()
                query = query.order_by(order_col)

            records = query.offset(skip).limit(limit).all()
            return [self.to_dict(record) for record in records]

        except Exception as e:
            logger.error(f"Error in get_multi: {str(e)}")
            raise

    @staticmethod
    def sanitize_float(value: Any) -> Optional[float]:
        if value is None:
            return None
        if isinstance(value, (float, Decimal)):
            if math.isnan(float(value)) or math.isinf(float(value)):
                return None
            return float(value)
        return value

    @staticmethod
    def sanitize_list(value: Any) -> Optional[List]:
        if value is None:
            return None
        if isinstance(value, list):
            return [str(item) for item in value if item is not None]
        if isinstance(value, str):
            return [value]
        return None

    def to_dict(self, obj: ModelType) -> Dict:
        result = {}
        for column in obj.__table__.columns:
            value = getattr(obj, column.name)

            if isinstance(value, (float, Decimal)):
                if value is None or math.isnan(float(value)) or math.isinf(float(value)):
                    result[column.name] = None
                else:
                    result[column.name] = float(value)
            elif isinstance(value, list):
                if value and isinstance(value[0], str) and value[0].startswith('{'):
                    cleaned = value[0].strip('{}').split(',')
                    result[column.name] = [item.strip('"') for item in cleaned if item]
                else:
                    result[column.name] = value
            else:
                result[column.name] = value

        return result

    def create(self, db: Session, obj_in: CreateSchemaType) -> Dict:
        try:
            obj_in_data = self.prepare_data_for_db(obj_in.model_dump())
            db_obj = self.model(**obj_in_data)
            db.add(db_obj)
            db.commit()
            db.refresh(db_obj)
            return self.to_dict(db_obj)
        except Exception as e:
            db.rollback()
            logger.error(f"Error creating {self.model.__name__}: {str(e)}")
            raise

    def get(self, db: Session, id: Any) -> Optional[ModelType]:
        try:
            obj = db.query(self.model).filter(self.model.id == id).first()
            if obj:
                return self.to_dict(obj)
            return None
        except Exception as e:
            logger.error(f"Error in get: {str(e)}")
            raise

    def update(self, db: Session, id: Any, obj_in: CreateSchemaType) -> Optional[Dict]:
        try:
            db_obj = db.query(self.model).filter(self.model.id == id).first()
            if db_obj:
                obj_data = self.prepare_data_for_db(obj_in.model_dump(exclude_unset=True))
                for key, value in obj_data.items():
                    setattr(db_obj, key, value)

                db.commit()
                db.refresh(db_obj)
                return self.to_dict(db_obj)
            return None
        except Exception as e:
            db.rollback()
            logger.error(f"Error updating {self.model.__name__}: {str(e)}")
            raise

    def delete(self, db: Session, id: Any) -> Optional[Dict]:
        try:
            obj = db.query(self.model).get(id)

            if obj:
                obj_dict = self.to_dict(obj)
                db.delete(obj)
                db.commit()
                return obj_dict
            return None
        except Exception as e:
            db.rollback()
            logger.error(f"Error deleting {self.model.__name__}: {str(e)}")
            raise

    @staticmethod
    def handle_float(value: Any) -> Optional[float]:
        if value is None:
            return None
        if isinstance(value, (float, Decimal)):
            try:
                float_val = float(value)
                if math.isnan(float_val) or math.isinf(float_val):
                    return None
                return float_val
            except (ValueError, TypeError):
                return None
        return value

    def prepare_data_for_db(self, data: Dict[str, Any]) -> Dict[str, Any]:
        prepared_data = {}
        for key, value in data.items():
            if isinstance(value, (float, Decimal)):
                prepared_data[key] = self.handle_float(value)
            elif isinstance(value, list):
                prepared_data[key] = [str(item) for item in value if item] or None
            else:
                prepared_data[key] = value
        return prepared_data


class CRUDInvestor(CRUDBase[models.Investor, schemas.InvestorCreate]):
    def get_by_email(self, db: Session, email: str) -> Optional[models.Investor]:
        return db.query(models.Investor).filter(models.Investor.email == email).first()

    def get_by_industry(self, db: Session, industry: str) -> List[models.Investor]:
        return db.query(models.Investor).filter(
            models.Investor.industry_preferences.overlap([industry])
        ).all()


class CRUDInvestmentFund(CRUDBase[models.InvestmentFund, schemas.InvestmentFundCreate]):
    def get_by_firm_email(self, db: Session, firm_email: str) -> Optional[models.InvestmentFund]:
        return db.query(models.InvestmentFund).filter(
            models.InvestmentFund.firm_email == firm_email
        ).first()

    def get_by_firm_name(self, db: Session, firm_name: str) -> Optional[models.InvestmentFund]:
        return db.query(models.InvestmentFund).filter(
            models.InvestmentFund.firm_name == firm_name
        ).first()


class CRUDSavedList(CRUDBase[models.SavedList, schemas.SavedListCreate]):
    def add_investor_to_list(self, db: Session, list_id: int, investor_id: int) -> bool:
        try:
            saved_list = db.query(models.SavedList).filter(models.SavedList.id == list_id).first()
            investor = db.query(models.Investor).filter(models.Investor.id == investor_id).first()

            if saved_list and investor:
                if investor not in saved_list.saved_investors:
                    saved_list.saved_investors.append(investor)
                    db.commit()
                return True
            return False
        except Exception as e:
            db.rollback()
            logger.error(f"Error adding investor to list: {str(e)}")
            raise

    def add_fund_to_list(self, db: Session, list_id: int, fund_id: int) -> bool:
        try:
            saved_list = db.query(models.SavedList).filter(models.SavedList.id == list_id).first()
            fund = db.query(models.InvestmentFund).filter(models.InvestmentFund.id == fund_id).first()

            if saved_list and fund:
                if fund not in saved_list.saved_funds:
                    saved_list.saved_funds.append(fund)
                    db.commit()
                return True
            return False
        except Exception as e:
            db.rollback()
            logger.error(f"Error adding fund to list: {str(e)}")
            raise

    def remove_investor_from_list(self, db: Session, list_id: int, investor_id: int) -> bool:
        try:
            saved_list = db.query(models.SavedList).filter(models.SavedList.id == list_id).first()
            investor = db.query(models.Investor).filter(models.Investor.id == investor_id).first()

            if saved_list and investor and investor in saved_list.saved_investors:
                saved_list.saved_investors.remove(investor)
                db.commit()
                return True
            return False
        except Exception as e:
            db.rollback()
            logger.error(f"Error removing investor from list: {str(e)}")
            raise

    def remove_fund_from_list(self, db: Session, list_id: int, fund_id: int) -> bool:
        try:
            saved_list = db.query(models.SavedList).filter(models.SavedList.id == list_id).first()
            fund = db.query(models.InvestmentFund).filter(models.InvestmentFund.id == fund_id).first()

            if saved_list and fund and fund in saved_list.saved_funds:
                saved_list.saved_funds.remove(fund)
                db.commit()
                return True
            return False
        except Exception as e:
            db.rollback()
            logger.error(f"Error removing fund from list: {str(e)}")
            raise


# Create instances
saved_list = CRUDSavedList(models.SavedList)
investor = CRUDInvestor(models.Investor)
investment_fund = CRUDInvestmentFund(models.InvestmentFund)

================
File: database.py
================
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker, Session, declarative_base
import os
from dotenv import load_dotenv
import logging
import traceback
from fastapi import HTTPException

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig()
logger = logging.getLogger("sqlalchemy.engine")

# Get database URL from environment variables with fallback
SQLALCHEMY_DATABASE_URL = os.getenv(
    "DATABASE_URL",
    "postgresql://investor_admin:your_secure_password@localhost/investor_db"
)

# Create engine with proper configuration
engine = create_engine(
    SQLALCHEMY_DATABASE_URL,
    pool_pre_ping=True,  # Enable connection health checks
    pool_size=5,  # Maximum number of database connections in the pool
    max_overflow=10  # Maximum number of connections that can be created beyond pool_size
)

# Create SessionLocal class with proper configuration
SessionLocal = sessionmaker(
    autocommit=False,
    autoflush=False,
    bind=engine,
    expire_on_commit=False
)

# Create Base class for declarative models
Base = declarative_base()


def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


def test_db_connection():
    """Test database connection"""
    try:
        logger.info("Testing database connection...")
        db = SessionLocal()
        db.execute(text("SELECT 1"))
        db.close()
        logger.info("Database connection successful!")
        return True
    except Exception as e:
        logger.error(f"Database connection failed: {str(e)}")
        logger.error(traceback.format_exc())
        return False

================
File: docker-compose.yml
================
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - ENVIRONMENT=${ENVIRONMENT}
    depends_on:
      db:
        condition: service_healthy
    volumes:
      - ./data:/app/data
    restart: unless-stopped
    networks:
      - investor-network

  db:
    image: postgres:15-alpine
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    ports:
      - "5433:5432"
    networks:
      - investor-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  postgres_data:

networks:
  investor-network:
    driver: bridge

================
File: Dockerfile
================
# Use Python 3.11 slim image as base
FROM python:3.11-slim

# Set working directory in container
WORKDIR /app

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PORT=8000

# Install system dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    build-essential \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

# Install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy project files
COPY . .

# Create non-root user for security
RUN adduser --disabled-password --gecos "" appuser
RUN chown -R appuser:appuser /app
USER appuser

# Expose port
EXPOSE $PORT

# Run the application
CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]

================
File: models.py
================
from sqlalchemy import Float, Text, Column, Integer, String, ForeignKey, Table, DateTime, Boolean
from sqlalchemy.dialects.postgresql import ARRAY as PG_ARRAY
from sqlalchemy.orm import relationship
from database import Base
from datetime import datetime, UTC

# Association tables for many-to-many relationships
saved_investors_association = Table(
    'saved_investors_association',
    Base.metadata,
    Column('list_id', Integer, ForeignKey('saved_lists.id')),
    Column('investor_id', Integer, ForeignKey('investors.id'))
)

saved_funds_association = Table(
    'saved_funds_association',
    Base.metadata,
    Column('list_id', Integer, ForeignKey('saved_lists.id')),
    Column('fund_id', Integer, ForeignKey('investment_funds.id'))
)


class SavedList(Base):
    __tablename__ = "saved_lists"

    id = Column(Integer, primary_key=True, index=True)
    name = Column(String, nullable=False)
    description = Column(String, nullable=True)
    created_at = Column(DateTime, default=datetime.now(UTC))
    updated_at = Column(DateTime, default=datetime.now(UTC), onupdate=datetime.now(UTC))
    list_type = Column(String, nullable=False)  # 'investor' or 'fund'

    # Relationships
    saved_investors = relationship("Investor", secondary=saved_investors_association)
    saved_funds = relationship("InvestmentFund", secondary=saved_funds_association)


class Investor(Base):
    __tablename__ = "investors"

    id = Column(Integer, primary_key=True, index=True)
    prefix = Column(String, nullable=True)
    first_name = Column(String)
    last_name = Column(String)
    gender = Column(String, nullable=True)
    contact_title = Column(String, nullable=True)
    email = Column(String, index=True)
    phone = Column(String, nullable=True)
    address = Column(String, nullable=True)
    office_website = Column(String, nullable=True)
    firm_name = Column(String, nullable=True)
    city = Column(String, nullable=True)
    state = Column(String, nullable=True)
    country = Column(String, nullable=True)
    type_of_firm = Column(String, nullable=True)
    type_of_financing = Column(PG_ARRAY(String), nullable=True)
    industry_preferences = Column(PG_ARRAY(String), nullable=True)
    geographic_preferences = Column(PG_ARRAY(String), nullable=True)
    stage_preferences = Column(PG_ARRAY(String), nullable=True)
    capital_managed = Column(Float, nullable=True)
    min_investment = Column(Float, nullable=True)
    max_investment = Column(Float, nullable=True)
    number_of_investors = Column(Float, nullable=True)


class InvestmentFund(Base):
    __tablename__ = "investment_funds"

    id = Column(Integer, primary_key=True, index=True)
    full_name = Column(String)
    title = Column(String, nullable=True)
    contact_email = Column(String, index=True)
    contact_phone = Column(String, nullable=True)
    firm_name = Column(String)
    firm_email = Column(String, index=True, nullable=True)
    firm_phone = Column(String, nullable=True)
    firm_website = Column(String, nullable=True)
    firm_address = Column(String, nullable=True)
    firm_city = Column(String, nullable=True)
    firm_state = Column(String, nullable=True)
    firm_zip = Column(String, nullable=True)
    firm_country = Column(String, nullable=True)
    office_type = Column(String, nullable=True)
    financing_type = Column(PG_ARRAY(String), nullable=True)
    industry_preferences = Column(PG_ARRAY(String), nullable=True)
    geographic_preferences = Column(PG_ARRAY(String), nullable=True)
    stage_preferences = Column(PG_ARRAY(String), nullable=True)
    capital_managed = Column(Float, nullable=True)
    min_investment = Column(Float, nullable=True)
    max_investment = Column(Float, nullable=True)
    firm_type = Column(String, nullable=True)
    number_of_investors = Column(Float, nullable=True)
    gender_ratio = Column(String, nullable=True)


class User(Base):
    __tablename__ = "users"

    id = Column(Integer, primary_key=True, index=True)
    email = Column(String, unique=True, index=True)
    first_name = Column(String)
    last_name = Column(String)
    hashed_password = Column(String)
    is_active = Column(Boolean, default=True)
    is_verified = Column(Boolean, default=False)
    created_at = Column(DateTime, default=datetime.now(UTC))
    last_login = Column(DateTime, nullable=True)
    verification_token = Column(String, nullable=True)
    reset_token = Column(String, nullable=True)
    reset_token_expires = Column(DateTime, nullable=True)
    profile_photo = Column(String, nullable=True)
    is_google_auth = Column(Boolean, default=False)

    refresh_tokens = relationship("RefreshToken", back_populates="user")


class RefreshToken(Base):
    __tablename__ = "refresh_tokens"

    id = Column(Integer, primary_key=True, index=True)
    token = Column(String, unique=True, index=True)
    user_id = Column(Integer, ForeignKey("users.id"))
    expires_at = Column(DateTime)
    created_at = Column(DateTime, default=datetime.now(UTC))
    revoked = Column(Boolean, default=False)

    # Relationship
    user = relationship("User", back_populates="refresh_tokens")

================
File: requirements.txt
================
fastapi~=0.104.1
uvicorn[standard]==0.24.0
sqlalchemy~=2.0.23
psycopg2-binary==2.9.9
pydantic~=2.9.2
python-dotenv==1.0.0
typing-extensions==4.8.0
email-validator==2.1.0.post1
python-jose[cryptography]==3.4.0
passlib[bcrypt]==1.7.4
python-multipart==0.0.19
alembic
pytest==7.4.3
httpx==0.25.1
pandas~=2.2.3

auth~=0.5.3
bcrypt~=4.3.0
jose~=1.0.0
starlette~=0.40.0


google-auth==2.22.0
google-auth-oauthlib==1.0.0
requests==2.32.0
watchtower==2.0.1
itsdangerous==2.2.0

================
File: schemas.py
================
from enum import Enum
from typing import Optional, List
from pydantic import BaseModel, ConfigDict, Field, EmailStr
from datetime import datetime


###########################################
# Investment Fund Filter Enums
###########################################

class InvestmentFundCity(str, Enum):
    NEW_YORK = "New York"
    LONDON = "London"
    SAN_FRANCISCO = "San Francisco"
    CHICAGO = "Chicago"
    BOSTON = "Boston"
    PARIS = "Paris"
    PALO_ALTO = "Palo Alto"
    SHANGHAI = "Shanghai"
    TORONTO = "Toronto"
    MENLO_PARK = "Menlo Park"
    DALLAS = "Dallas"
    TOKYO = "Tokyo"
    BEIJING = "Beijing"
    LOS_ANGELES = "Los Angeles"
    HOUSTON = "Houston"
    MUNICH = "Munich"
    STOCKHOLM = "Stockholm"
    MUMBAI = "Mumbai"
    CAMBRIDGE = "Cambridge"
    AUSTIN = "Austin"


class InvestmentFundState(str, Enum):
    CALIFORNIA = "California"
    NEW_YORK = "New York"
    MASSACHUSETTS = "Massachusetts"
    TEXAS = "Texas"
    ILLINOIS = "Illinois"
    ONTARIO = "Ontario"
    CONNECTICUT = "Connecticut"
    FLORIDA = "Florida"
    PENNSYLVANIA = "Pennsylvania"
    COLORADO = "Colorado"
    MICHIGAN = "Michigan"
    OHIO = "Ohio"
    GEORGIA = "Georgia"
    MARYLAND = "Maryland"
    VIRGINIA = "Virginia"
    NEW_SOUTH_WALES = "New South Wales"
    NORTH_CAROLINA = "North Carolina"
    WASHINGTON = "Washington"
    BRITISH_COLUMBIA = "British Columbia"
    NEW_JERSEY = "New Jersey"


class InvestmentFundCountry(str, Enum):
    UNITED_STATES = "United States"
    UNITED_KINGDOM = "United Kingdom"
    GERMANY = "Germany"
    CANADA = "Canada"
    CHINA = "China"
    FRANCE = "France"
    INDIA = "India"
    ISRAEL = "Israel"
    HONG_KONG = "Hong Kong"
    JAPAN = "Japan"
    SINGAPORE = "Singapore"
    SWEDEN = "Sweden"
    AUSTRALIA = "Australia"
    NETHERLANDS = "Netherlands"
    SPAIN = "Spain"
    BELGIUM = "Belgium"
    SWITZERLAND = "Switzerland"
    FINLAND = "Finland"
    ITALY = "Italy"
    KOREA = "Korea"


class InvestmentFundLocationPreference(str, Enum):
    UNITED_STATES = "United States"
    EUROPE = "Europe"
    CANADA = "Canada"
    UNITED_KINGDOM = "United Kingdom"
    CHINA = "China"
    GERMANY = "Germany"
    UNITED_STATES_CALIFORNIA = "United States (California)"
    ASIA = "Asia"
    FRANCE = "France"
    UNITED_STATES_MID_ATLANTIC = "United States (Mid-Atlantic)"
    UNITED_STATES_MIDWEST = "United States (Midwest)"
    ISRAEL = "Israel"
    UNITED_STATES_SOUTHWEST = "United States (Southwest)"
    UNITED_STATES_SOUTHEAST = "United States (Southeast)"
    UNITED_STATES_NORTHEAST = "United States (Northeast)"
    SWITZERLAND = "Switzerland"
    SWEDEN = "Sweden"
    INDIA = "India"
    NETHERLANDS = "Netherlands"
    AUSTRALIA = "Australia"


class InvestmentFundFinancingType(str, Enum):
    DEBT = "Debt"
    EQUITY = "Equity"
    FUND_OF_FUNDS = 'Fund of Funds'
    LEASES = 'Leases'
    MEZZANINE = 'Mezzanine'
    ROYALTIES = 'Royalties'


class InvestmentFundIndustryPreference(str, Enum):
    IT_SERVICES = "IT Services"
    COMMUNICATIONS_NETWORKING = "Communications & Networking"
    SOFTWARE = "Software"
    HEALTHCARE_SERVICES = "Healthcare Services"
    CONSUMER_PRODUCTS_SERVICES = "Consumer Products & Services"
    BUSINESS_PRODUCTS_SERVICES = "Business Products & Services"
    MEDIA_ENTERTAINMENT = "Media & Entertainment"
    DISTRIBUTION_RETAIL = "Distribution/Retailing"
    FINANCIAL_SERVICES = "Financial Services"
    ENERGY_NATURAL_RESOURCES = "Energy/Natural Resources"
    DIVERSIFIED = "Diversified"
    INTERNET_TECHNOLOGY = "Internet Technology"
    CHEMICALS_MATERIALS = "Chemicals & Materials"
    MANUFACTURING = "Manufacturing"
    BIOTECHNOLOGY = "Biotechnology"
    ELECTRONICS = "Electronics"
    MEDICAL_DEVICES_EQUIPMENT = "Medical Devices & Equipment"
    INDUSTRIAL_PRODUCTS_SERVICES = "Industrial Products & Services"
    FOOD_SERVICES_PRODUCTS = "Food Services & Products"
    ENVIRONMENT = "Environment"


class InvestmentFundType(str, Enum):
    PRIVATE_EQUITY = "Private Equity Fund"
    VENTURE_CAPITAL = "Venture Capital Fund"
    INVESTMENT_BANK = "Investment Bank"
    SMALL_BUSINESS = "Small Business Investment Company"
    STARTUP_STUDIO = "Startup Studio"
    GOVERNMENT = "Government Organization"


class InvestmentFundStagePreference(str, Enum):
    EXPANSION = "Expansion"
    MBO_LBO = "MBO/LBO"
    EARLY_STAGE = "Early Stage"
    STARTUP = "Startup"
    SEED = "Seed"
    ACQUISITION = "Acquisition"
    RECAPITALIZATION = "Recapitalization"
    LATER_STAGE = "Later Stage"
    RESTRUCTURING = "Restructuring"
    CORPORATE_DIVESTITURE = "Corporate Divestiture"
    CONSOLIDATION = "Consolidation"
    GOING_PRIVATE = "Going Private"
    SPECIAL_SITUATIONS = "Special Situations"
    TURNAROUND = "Turnaround"
    PIPE = "PIPE"
    SPINOUT = "Spinout"
    SECONDARY_PURCHASE = "Secondary Purchase"
    OWNERSHIP_TRANSITION = "Ownership Transition"
    DISTRESSED_DEBT = "Distressed Debt"
    PRIVATIZATION = "Privatization"


class InvestmentFundAssetsUnderManagement(str, Enum):
    TIER_1B_PLUS = "$1B+"
    TIER_100M_500M = "$100M - $500M"
    TIER_500M_1B = "$500M - $1B"
    TIER_25M_100M = "$25M - $100M"
    TIER_0_25M = "$0 - $25M"


class InvestmentFundMinInvestment(str, Enum):
    TIER_5M_20M = "$5M - $20M"
    TIER_1M_5M = "$1M - $5M"
    TIER_250K_1M = "$250K - $1M"
    TIER_20M_PLUS = "$20M+"
    TIER_0_250K = "$0 - $250K"


class InvestmentFundMaxInvestment(str, Enum):
    TIER_1M_10M = "$1M - $10M"
    TIER_10M_25M = "$10M - $25M"
    TIER_25M_100M = "$25M - $100M"
    TIER_100M_PLUS = "$100M+"
    TIER_0_1M = "$0 - $1M"


class InvestmentFundNumberOfInvestors(str, Enum):
    TIER_1_10 = "1 - 10"
    TIER_10_20 = "10 - 20"
    TIER_20_30 = "20 - 30"
    TIER_30_40 = "30 - 40"


class InvestmentFundGenderRatio(str, Enum):
    NO_FEMALE = "0% female"
    FEMALE_25 = "25% female"
    FEMALE_20 = "20% female"
    FEMALE_33 = "33% female"
    FEMALE_17 = "17% female"
    FEMALE_13 = "13% female"
    FEMALE_50 = "50% female"
    FEMALE_14 = "14% female"
    FEMALE_11 = "11% female"
    FEMALE_8 = "8% female"
    FEMALE_9 = "9% female"
    FEMALE_10 = "10% female"
    FEMALE_6 = "6% female"
    FEMALE_100 = "100% female"
    FEMALE_40 = "40% female"
    FEMALE_29 = "29% female"
    FEMALE_22 = "22% female"
    FEMALE_7 = "7% female"
    FEMALE_15 = "15% female"
    FEMALE_4 = "4% female"


###########################################
# Investor Filter Enums
###########################################

class InvestorCity(str, Enum):
    NEW_YORK = "New York"
    LONDON = "London"
    SAN_FRANCISCO = "San Francisco"
    CHICAGO = "Chicago"
    BOSTON = "Boston"
    PARIS = "Paris"
    TORONTO = "Toronto"
    PALO_ALTO = "Palo Alto"
    SHANGHAI = "Shanghai"
    MENLO_PARK = "Menlo Park"
    DALLAS = "Dallas"
    LOS_ANGELES = "Los Angeles"
    HOUSTON = "Houston"
    STOCKHOLM = "Stockholm"
    MUNICH = "Munich"
    AMSTERDAM = "Amsterdam"
    BEIJING = "Beijing"
    GREENWICH = "Greenwich"
    MUMBAI = "Mumbai"
    TOKYO = "Tokyo"


class InvestorState(str, Enum):
    CALIFORNIA = "California"
    NEW_YORK = "New York"
    MASSACHUSETTS = "Massachusetts"
    ILLINOIS = "Illinois"
    TEXAS = "Texas"
    CONNECTICUT = "Connecticut"
    ONTARIO = "Ontario"
    PENNSYLVANIA = "Pennsylvania"
    FLORIDA = "Florida"
    NORTH_CAROLINA = "North Carolina"
    COLORADO = "Colorado"
    MARYLAND = "Maryland"
    MICHIGAN = "Michigan"
    NEW_SOUTH_WALES = "New South Wales"
    GEORGIA = "Georgia"
    OHIO = "Ohio"
    VIRGINIA = "Virginia"
    MINNESOTA = "Minnesota"
    DISTRICT_OF_COLUMBIA = "District of Columbia"
    MISSOURI = "Missouri"


class InvestorCountry(str, Enum):
    UNITED_STATES = "United States"
    UNITED_KINGDOM = "United Kingdom"
    FRANCE = "France"
    GERMANY = "Germany"
    CANADA = "Canada"
    CHINA = "China"
    NETHERLANDS = "Netherlands"
    INDIA = "India"
    SWEDEN = "Sweden"
    ISRAEL = "Israel"
    SPAIN = "Spain"
    AUSTRALIA = "Australia"
    SINGAPORE = "Singapore"
    BELGIUM = "Belgium"
    FINLAND = "Finland"
    JAPAN = "Japan"
    HONG_KONG = "Hong Kong"
    ITALY = "Italy"
    SWITZERLAND = "Switzerland"
    NORWAY = "Norway"


class InvestorLocationPreference(str, Enum):
    UNITED_STATES = "United States"
    EUROPE = "Europe"
    CANADA = "Canada"
    UNITED_KINGDOM = "United Kingdom"
    GERMANY = "Germany"
    CHINA = "China"
    FRANCE = "France"
    UNITED_STATES_CALIFORNIA = "United States (California)"
    ASIA = "Asia"
    UNITED_STATES_MID_ATLANTIC = "United States (Mid-Atlantic)"
    UNITED_STATES_MIDWEST = "United States (Midwest)"
    UNITED_STATES_SOUTHEAST = "United States (Southeast)"
    ISRAEL = "Israel"
    SWITZERLAND = "Switzerland"
    UNITED_STATES_SOUTHWEST = "United States (Southwest)"
    NETHERLANDS = "Netherlands"
    SWEDEN = "Sweden"
    UNITED_STATES_NORTHEAST = "United States (Northeast)"
    FINLAND = "Finland"
    AUSTRIA = "Austria"


class InvestorIndustryPreference(str, Enum):
    IT_SERVICES = "IT Services"
    COMMUNICATIONS_NETWORKING = "Communications & Networking"
    HEALTHCARE_SERVICES = "Healthcare Services"
    BUSINESS_PRODUCTS_SERVICES = "Business Products & Services"
    CONSUMER_PRODUCTS_SERVICES = "Consumer Products & Services"
    DISTRIBUTION_RETAIL = "Distribution/Retailing"
    FINANCIAL_SERVICES = "Financial Services"
    SOFTWARE = "Software"
    DIVERSIFIED = "Diversified"
    MEDIA_ENTERTAINMENT = "Media & Entertainment"
    ENERGY_NATURAL_RESOURCES = "Energy/Natural Resources"
    MANUFACTURING = "Manufacturing"
    INTERNET_TECHNOLOGY = "Internet Technology"
    CHEMICALS_MATERIALS = "Chemicals & Materials"
    INDUSTRIAL_PRODUCTS_SERVICES = "Industrial Products & Services"
    ELECTRONICS = "Electronics"
    BIOTECHNOLOGY = "Biotechnology"
    MEDICAL_DEVICES_EQUIPMENT = "Medical Devices & Equipment"
    FOOD_SERVICES_PRODUCTS = "Food Services & Products"
    EDUCATION_TRAINING = "Education & Training"


class InvestorFundType(str, Enum):
    PRIVATE_EQUITY = "Private Equity Fund"
    VENTURE_CAPITAL = "Venture Capital Fund"
    SMALL_BUSINESS = "Small Business Investment Company"
    INVESTMENT_BANK = "Investment Bank"
    GOVERNMENT = "Government Organization"
    STARTUP_STUDIO = "Startup Studio"


class InvestorFinancingType(str, Enum):
    DEBT = "Debt"
    EQUITY = "Equity"
    FUND_OF_FUNDS = 'Fund of Funds'
    LEASES = 'Leases'
    MEZZANINE = 'Mezzanine'
    ROYALTIES = 'Royalties'


class InvestorStagePreference(str, Enum):
    EXPANSION = "Expansion"
    MBO_LBO = "MBO/LBO"
    EARLY_STAGE = "Early Stage"
    STARTUP = "Startup"
    SEED = "Seed"
    RECAPITALIZATION = "Recapitalization"
    ACQUISITION = "Acquisition"
    LATER_STAGE = "Later Stage"
    CORPORATE_DIVESTITURE = "Corporate Divestiture"
    RESTRUCTURING = "Restructuring"
    CONSOLIDATION = "Consolidation"
    GOING_PRIVATE = "Going Private"
    SPECIAL_SITUATIONS = "Special Situations"
    TURNAROUND = "Turnaround"
    PIPE = "PIPE"
    SPINOUT = "Spinout"
    OWNERSHIP_TRANSITION = "Ownership Transition"
    SECONDARY_PURCHASE = "Secondary Purchase"
    PRIVATIZATION = "Privatization"
    DISTRESSED_DEBT = "Distressed Debt"


class InvestorAssetsUnderManagement(str, Enum):
    TIER_1B_PLUS = "$1B+"
    TIER_100M_500M = "$100M - $500M"
    TIER_500M_1B = "$500M - $1B"
    TIER_25M_100M = "$25M - $100M"
    TIER_0_25M = "$0 - $25M"


class InvestorMinInvestment(str, Enum):
    TIER_5M_20M = "$5M - $20M"
    TIER_20M_PLUS = "$20M+"
    TIER_1M_5M = "$1M - $5M"
    TIER_250K_1M = "$250K - $1M"
    TIER_0_250K = "$0 - $250K"


class InvestorMaxInvestment(str, Enum):
    TIER_25M_100M = "$25M - $100M"
    TIER_10M_25M = "$10M - $25M"
    TIER_100M_PLUS = "$100M+"
    TIER_1M_10M = "$1M - $10M"
    TIER_0_1M = "$0 - $1M"


class InvestorNumberOfInvestors(str, Enum):
    TIER_1_10 = "1 - 10"
    TIER_10_20 = "10 - 20"
    TIER_20_30 = "20 - 30"
    TIER_30_40 = "30 - 40"


class InvestorJobTitle(str, Enum):
    PARTNER = "Partner"
    MANAGING_DIRECTOR = "Managing Director"
    MANAGING_PARTNER = "Managing Partner"
    ASSOCIATE = "Associate"
    PRINCIPAL = "Principal"
    VICE_PRESIDENT = "Vice President"
    SENIOR_ASSOCIATE = "Senior Associate"
    GENERAL_PARTNER = "General Partner"
    INVESTMENT_MANAGER = "Investment Manager"
    INVESTMENT_DIRECTOR = "Investment Director"
    DIRECTOR = "Director"
    CFO = "CFO"
    ANALYST = "Analyst"
    CEO = "CEO"
    FOUNDING_PARTNER = "Founding Partner"
    VENTURE_PARTNER = "Venture Partner"
    OPERATING_PARTNER = "Operating Partner"
    PRESIDENT = "President"
    CHAIRMAN = "Chairman"
    SENIOR_MANAGING_DIRECTOR = "Senior Managing Director"


class InvestorGender(str, Enum):
    MALE = "Male"
    FEMALE = "Female"


###########################################
# Filter Parameters Models
###########################################

class LocationFilter(BaseModel):
    """Location filter parameters"""
    city: Optional[List[str]] = None
    state: Optional[List[str]] = None
    country: Optional[List[str]] = None
    location_preferences: Optional[List[str]] = None


class ContactInfoFilter(BaseModel):
    """Contact information filter parameters"""
    hasEmail: Optional[bool] = None
    hasPhone: Optional[bool] = None
    hasAddress: Optional[bool] = None


class IndustryFilter(BaseModel):
    """Industry preferences filter parameters"""
    industries: Optional[List[str]] = None


class StagePreferencesFilter(BaseModel):
    """Investment stage preferences filter parameters"""
    stages: Optional[List[str]] = None


class FundTypeFilter(BaseModel):
    """Fund type filter parameters"""
    types: Optional[List[str]] = None


class InvestmentRangesFilter(BaseModel):
    """Investment range filter parameters"""
    assetsUnderManagement: Optional[List[str]] = None
    minInvestment: Optional[List[str]] = None
    maxInvestment: Optional[List[str]] = None


class InvestorCountFilter(BaseModel):
    """Number of investors filter parameters"""
    range: Optional[List[str]] = None


class GenderRatioFilter(BaseModel):
    """Gender ratio filter parameters"""
    ratio: Optional[List[str]] = None


class GenderFilter(BaseModel):
    """Gender filter parameters"""
    gender: Optional[str] = None


class JobTitleFilter(BaseModel):
    """Job title filter parameters"""
    titles: Optional[List[str]] = None


# Main filter parameter models
class InvestorFilterParams(BaseModel):
    """Complete investor filter parameters"""
    searchTerm: Optional[str] = None
    location: Optional[LocationFilter] = None
    contactInfo: Optional[ContactInfoFilter] = None
    industry: Optional[IndustryFilter] = None
    fundType: Optional[FundTypeFilter] = None
    stages: Optional[StagePreferencesFilter] = None
    investmentRanges: Optional[InvestmentRangesFilter] = None
    jobTitle: Optional[JobTitleFilter] = None
    gender: Optional[GenderFilter] = None

    class Config:
        use_enum_values = True


###########################################
# Base Models
###########################################

class InvestorBase(BaseModel):
    prefix: Optional[str] = None
    first_name: str
    last_name: str
    gender: Optional[str] = None
    contact_title: Optional[str] = None
    email: str
    phone: Optional[str] = None
    address: Optional[str] = None
    office_website: Optional[str] = None
    firm_name: Optional[str] = None
    city: Optional[str] = None
    state: Optional[str] = None
    country: Optional[str] = None
    type_of_firm: Optional[str] = None
    type_of_financing: Optional[List[str]] = None
    industry_preferences: Optional[List[str]] = None
    geographic_preferences: Optional[List[str]] = None
    stage_preferences: Optional[List[str]] = None
    capital_managed: Optional[float] = None
    min_investment: Optional[float] = None
    max_investment: Optional[float] = None
    number_of_investors: Optional[float] = None


class InvestorCreate(InvestorBase):
    pass


class Investor(InvestorBase):
    id: int

    model_config = ConfigDict(from_attributes=True)


class InvestmentFundBase(BaseModel):
    full_name: str
    title: Optional[str] = None
    contact_email: str
    contact_phone: Optional[str] = None
    firm_name: str
    firm_email: Optional[str] = None
    firm_phone: Optional[str] = None
    firm_website: Optional[str] = None
    firm_address: Optional[str] = None
    firm_city: Optional[str] = None
    firm_state: Optional[str] = None
    firm_zip: Optional[str] = None
    firm_country: Optional[str] = None
    office_type: Optional[str] = None
    financing_type: Optional[str] = None
    industry_preferences: Optional[List[str]] = None
    geographic_preferences: Optional[List[str]] = None
    stage_preferences: Optional[List[str]] = None
    capital_managed: Optional[float] = None
    min_investment: Optional[float] = None
    max_investment: Optional[float] = None
    firm_type: Optional[str] = None
    number_of_investors: Optional[float] = None
    gender_ratio: Optional[str] = None


class InvestmentFundCreate(InvestmentFundBase):
    pass


class InvestmentFund(InvestmentFundBase):
    id: int
    model_config = ConfigDict(
        from_attributes=True,
        json_encoders={float: lambda v: v if v is not None else None}
    )


class InvestmentFundFilterParams(BaseModel):
    """Complete investment fund filter parameters"""
    searchTerm: Optional[str] = None
    location: Optional[LocationFilter] = None
    contactInfo: Optional[ContactInfoFilter] = None
    industry: Optional[IndustryFilter] = None
    fundType: Optional[FundTypeFilter] = None
    stages: Optional[StagePreferencesFilter] = None
    investmentRanges: Optional[InvestmentRangesFilter] = None
    investorCount: Optional[InvestorCountFilter] = None
    genderRatio: Optional[GenderRatioFilter] = None

    class Config:
        use_enum_values = True


class SavedListBase(BaseModel):
    """Base class for saved lists"""
    name: str
    description: Optional[str] = None
    list_type: str  # 'investor' or 'fund'


class SavedListCreate(SavedListBase):
    """Create schema for saved lists"""
    pass


class SavedList(SavedListBase):
    """Response schema for saved lists"""
    id: int
    created_at: datetime
    updated_at: datetime

    model_config = ConfigDict(from_attributes=True)


class UserBase(BaseModel):
    email: EmailStr
    first_name: str
    last_name: str


class UserCreate(UserBase):
    password: str = Field(..., min_length=8)


class UserLogin(BaseModel):
    email: EmailStr
    password: str


class UserUpdate(BaseModel):
    first_name: Optional[str] = None
    last_name: Optional[str] = None
    email: Optional[EmailStr] = None
    profile_photo: Optional[str] = None


class PasswordUpdate(BaseModel):
    current_password: str
    new_password: str = Field(..., min_length=8)
    confirm_password: str


class PasswordReset(BaseModel):
    email: EmailStr


class PasswordResetConfirm(BaseModel):
    token: str
    new_password: str = Field(..., min_length=8)
    confirm_password: str


class VerifyEmail(BaseModel):
    token: str


class Token(BaseModel):
    access_token: str
    token_type: str
    refresh_token: Optional[str] = None


class UserResponse(UserBase):
    id: int
    is_active: bool
    is_verified: bool
    created_at: datetime
    profile_photo: Optional[str] = None
    is_google_auth: Optional[bool] = False

    model_config = ConfigDict(from_attributes=True)


class GoogleAccountLink(BaseModel):
    email: EmailStr
    password: str


class SetPasswordForOAuthUser(BaseModel):
    password: str = Field(..., min_length=8)
    confirm_password: str
